{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab5f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries and Setup Directories\n",
    "# Standard Library\n",
    "import os\n",
    "import pickle\n",
    "import datetime as dt\n",
    "import subprocess\n",
    "import sys\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Data Handling and Numerical Computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "# Machine Learning and Deep Learning\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, GRU, SimpleRNN, Input, LSTM, Dense, Dropout, Input, LayerNormalization, BatchNormalization\n",
    "\n",
    "# Financial Data\n",
    "import yfinance as yf\n",
    "import pandas_datareader as web\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure necessary directories exist\n",
    "DATA_DIR = \"data\"\n",
    "MODEL_DIR = \"models\"\n",
    "for directory in [DATA_DIR, MODEL_DIR]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Created directory: {directory}\")\n",
    "\n",
    "# Install plotly if not already installed\n",
    "def install_package(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"‚úÖ {package} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"‚úÖ {package} installed successfully\")\n",
    "\n",
    "install_package('plotly')\n",
    "\n",
    "# Install sentiment analysis packages\n",
    "install_package('vaderSentiment')\n",
    "install_package('requests')\n",
    "install_package('python-dotenv')\n",
    "install_package('pyyaml')\n",
    "\n",
    "print(\"‚úÖ All required packages are ready!\")\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(f'{DATA_DIR}/stock_prediction.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add error handling wrapper\n",
    "def safe_execute(func, *args, **kwargs):\n",
    "    \"\"\"Safely execute functions with error handling\"\"\"\n",
    "    try:\n",
    "        return func(*args, **kwargs)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in {func.__name__}: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sentiment_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis Infrastructure Setup\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from datetime import datetime, timedelta\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create sentiment cache directory\n",
    "SENTIMENT_CACHE_DIR = \"data/sentiment_cache\"\n",
    "if not os.path.exists(SENTIMENT_CACHE_DIR):\n",
    "    os.makedirs(SENTIMENT_CACHE_DIR)\n",
    "    print(f\"Created directory: {SENTIMENT_CACHE_DIR}\")\n",
    "\n",
    "@dataclass\n",
    "class SentimentScore:\n",
    "    \"\"\"Data class for sentiment scores\"\"\"\n",
    "    compound: float  # Overall sentiment (-1 to 1)\n",
    "    positive: float  # Positive component (0 to 1)\n",
    "    negative: float  # Negative component (0 to 1)\n",
    "    neutral: float   # Neutral component (0 to 1)\n",
    "    confidence: float = 1.0  # Confidence in the score (0 to 1)\n",
    "\n",
    "@dataclass\n",
    "class NewsArticle:\n",
    "    \"\"\"Data class for news articles\"\"\"\n",
    "    title: str\n",
    "    content: str\n",
    "    published_at: datetime\n",
    "    source: str\n",
    "    url: str\n",
    "    relevance_score: float = 1.0\n",
    "\n",
    "@dataclass\n",
    "class SocialPost:\n",
    "    \"\"\"Data class for social media posts\"\"\"\n",
    "    text: str\n",
    "    created_at: datetime\n",
    "    platform: str\n",
    "    author: str\n",
    "    engagement_metrics: dict\n",
    "    is_spam: bool = False\n",
    "\n",
    "@dataclass\n",
    "class SentimentConfig:\n",
    "    \"\"\"Configuration for sentiment analysis\"\"\"\n",
    "    enabled: bool = True\n",
    "    news_sources: List[str] = field(default_factory=lambda: ['newsapi'])\n",
    "    social_platforms: List[str] = field(default_factory=lambda: ['twitter'])\n",
    "    sentiment_analyzer: str = 'vader'\n",
    "    cache_duration_hours: int = 24\n",
    "    max_articles_per_day: int = 50\n",
    "    max_posts_per_day: int = 100\n",
    "\n",
    "# Custom exceptions\n",
    "class SentimentAnalysisError(Exception):\n",
    "    \"\"\"Base exception for sentiment analysis errors\"\"\"\n",
    "    pass\n",
    "\n",
    "class APIRateLimitError(SentimentAnalysisError):\n",
    "    \"\"\"Raised when API rate limits are exceeded\"\"\"\n",
    "    pass\n",
    "\n",
    "class DataQualityError(SentimentAnalysisError):\n",
    "    \"\"\"Raised when sentiment data quality is poor\"\"\"\n",
    "    pass\n",
    "\n",
    "print(\"‚úÖ Sentiment analysis infrastructure setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sentiment_analyzer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analyzer Implementation\n",
    "class SentimentAnalyzer:\n",
    "    \"\"\"Processes text content to extract sentiment scores\"\"\"\n",
    "    \n",
    "    def __init__(self, analyzer_type: str = 'vader'):\n",
    "        self.analyzer_type = analyzer_type\n",
    "        if analyzer_type == 'vader':\n",
    "            self.analyzer = SentimentIntensityAnalyzer()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported analyzer type: {analyzer_type}\")\n",
    "    \n",
    "    def _preprocess_text(self, text: str) -> str:\n",
    "        \"\"\"Preprocess text for financial sentiment analysis\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        \n",
    "        # Basic cleaning\n",
    "        text = text.strip()\n",
    "        # Remove excessive whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        return text\n",
    "    \n",
    "    def analyze_text(self, text: str) -> SentimentScore:\n",
    "        \"\"\"Analyze sentiment of a single text\"\"\"\n",
    "        try:\n",
    "            processed_text = self._preprocess_text(text)\n",
    "            if not processed_text:\n",
    "                return SentimentScore(0.0, 0.0, 0.0, 1.0, 0.0)\n",
    "            \n",
    "            scores = self.analyzer.polarity_scores(processed_text)\n",
    "            return SentimentScore(\n",
    "                compound=scores['compound'],\n",
    "                positive=scores['pos'],\n",
    "                negative=scores['neg'],\n",
    "                neutral=scores['neu'],\n",
    "                confidence=1.0\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error analyzing text sentiment: {e}\")\n",
    "            return SentimentScore(0.0, 0.0, 0.0, 1.0, 0.0)\n",
    "    \n",
    "    def batch_analyze(self, texts: List[str]) -> List[SentimentScore]:\n",
    "        \"\"\"Analyze sentiment of multiple texts\"\"\"\n",
    "        return [self.analyze_text(text) for text in texts]\n",
    "\n",
    "print(\"‚úÖ SentimentAnalyzer class implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "news_api_client",
   "metadata": {},
   "outputs": [],
   "source": [
    "# News API Client Implementation\n",
    "class NewsAPIClient:\n",
    "    \"\"\"Fetches news articles from external APIs\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str = None, base_url: str = \"https://newsapi.org/v2\"):\n",
    "        self.api_key = api_key or os.getenv('NEWS_API_KEY')\n",
    "        self.base_url = base_url\n",
    "        self.session = requests.Session()\n",
    "        if self.api_key:\n",
    "            self.session.headers.update({'X-API-Key': self.api_key})\n",
    "    \n",
    "    def _build_query(self, symbol: str) -> str:\n",
    "        \"\"\"Build search query for company news\"\"\"\n",
    "        company_queries = {\n",
    "            'CBA.AX': 'Commonwealth Bank OR CBA OR \"Commonwealth Bank of Australia\"',\n",
    "        }\n",
    "        return company_queries.get(symbol, symbol.replace('.', ' '))\n",
    "    \n",
    "    def _handle_rate_limits(self, response) -> None:\n",
    "        \"\"\"Handle API rate limiting\"\"\"\n",
    "        if response.status_code == 429:\n",
    "            retry_after = int(response.headers.get('Retry-After', 60))\n",
    "            logging.warning(f\"Rate limit hit, waiting {retry_after} seconds\")\n",
    "            time.sleep(retry_after)\n",
    "            raise APIRateLimitError(\"Rate limit exceeded\")\n",
    "    \n",
    "    def fetch_news(self, query: str, from_date: str, to_date: str) -> List[NewsArticle]:\n",
    "        \"\"\"Fetch news articles for given query and date range\"\"\"\n",
    "        if not self.api_key:\n",
    "            logging.warning(\"No News API key provided, using mock data\")\n",
    "            return self._get_mock_news(query, from_date, to_date)\n",
    "        \n",
    "        try:\n",
    "            params = {\n",
    "                'q': query,\n",
    "                'from': from_date,\n",
    "                'to': to_date,\n",
    "                'sortBy': 'publishedAt',\n",
    "                'language': 'en',\n",
    "                'pageSize': 50\n",
    "            }\n",
    "            \n",
    "            response = self.session.get(f\"{self.base_url}/everything\", params=params)\n",
    "            self._handle_rate_limits(response)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            articles = []\n",
    "            \n",
    "            for article_data in data.get('articles', []):\n",
    "                try:\n",
    "                    article = NewsArticle(\n",
    "                        title=article_data.get('title', ''),\n",
    "                        content=article_data.get('description', '') or article_data.get('content', ''),\n",
    "                        published_at=datetime.fromisoformat(article_data['publishedAt'].replace('Z', '+00:00')),\n",
    "                        source=article_data.get('source', {}).get('name', 'Unknown'),\n",
    "                        url=article_data.get('url', ''),\n",
    "                        relevance_score=1.0\n",
    "                    )\n",
    "                    articles.append(article)\n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"Error parsing article: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            return articles\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching news: {e}\")\n",
    "            return self._get_mock_news(query, from_date, to_date)\n",
    "    \n",
    "    def _get_mock_news(self, query: str, from_date: str, to_date: str) -> List[NewsArticle]:\n",
    "        \"\"\"Generate mock news data for testing\"\"\"\n",
    "        mock_articles = [\n",
    "            NewsArticle(\n",
    "                title=f\"Commonwealth Bank reports strong quarterly results\",\n",
    "                content=\"Commonwealth Bank announced strong financial performance with increased profits and customer growth.\",\n",
    "                published_at=datetime.strptime(from_date, '%Y-%m-%d') + timedelta(days=1),\n",
    "                source=\"Financial Review\",\n",
    "                url=\"https://example.com/news1\",\n",
    "                relevance_score=0.9\n",
    "            ),\n",
    "            NewsArticle(\n",
    "                title=f\"CBA faces regulatory scrutiny over lending practices\",\n",
    "                content=\"Banking regulator announces investigation into Commonwealth Bank's lending procedures.\",\n",
    "                published_at=datetime.strptime(from_date, '%Y-%m-%d') + timedelta(days=2),\n",
    "                source=\"ABC News\",\n",
    "                url=\"https://example.com/news2\",\n",
    "                relevance_score=0.8\n",
    "            )\n",
    "        ]\n",
    "        return mock_articles\n",
    "\n",
    "print(\"‚úÖ NewsAPIClient class implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social_media_client",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Social Media Client Implementation\n",
    "class SocialMediaClient:\n",
    "    \"\"\"Collects social media posts mentioning the target company\"\"\"\n",
    "    \n",
    "    def __init__(self, platform: str = 'twitter', credentials: dict = None):\n",
    "        self.platform = platform\n",
    "        self.credentials = credentials or {}\n",
    "    \n",
    "    def _filter_relevant_posts(self, posts: List[SocialPost]) -> List[SocialPost]:\n",
    "        \"\"\"Filter posts for relevance to financial topics\"\"\"\n",
    "        financial_keywords = ['stock', 'price', 'earnings', 'profit', 'loss', 'dividend', 'market', 'trading']\n",
    "        relevant_posts = []\n",
    "        \n",
    "        for post in posts:\n",
    "            text_lower = post.text.lower()\n",
    "            if any(keyword in text_lower for keyword in financial_keywords):\n",
    "                relevant_posts.append(post)\n",
    "        \n",
    "        return relevant_posts\n",
    "    \n",
    "    def _detect_spam(self, post: SocialPost) -> bool:\n",
    "        \"\"\"Simple spam detection\"\"\"\n",
    "        spam_indicators = ['buy now', 'guaranteed profit', 'risk free', 'get rich quick']\n",
    "        text_lower = post.text.lower()\n",
    "        return any(indicator in text_lower for indicator in spam_indicators)\n",
    "    \n",
    "    def fetch_posts(self, query: str, start_date: str, end_date: str) -> List[SocialPost]:\n",
    "        \"\"\"Fetch social media posts for given query and date range\"\"\"\n",
    "        # For now, return mock data since we don't have API access\n",
    "        return self._get_mock_posts(query, start_date, end_date)\n",
    "    \n",
    "    def _get_mock_posts(self, query: str, start_date: str, end_date: str) -> List[SocialPost]:\n",
    "        \"\"\"Generate mock social media posts for testing\"\"\"\n",
    "        mock_posts = [\n",
    "            SocialPost(\n",
    "                text=\"CBA stock looking strong today! Great earnings report üìà\",\n",
    "                created_at=datetime.strptime(start_date, '%Y-%m-%d') + timedelta(days=1),\n",
    "                platform=\"twitter\",\n",
    "                author=\"investor123\",\n",
    "                engagement_metrics={\"likes\": 45, \"retweets\": 12},\n",
    "                is_spam=False\n",
    "            ),\n",
    "            SocialPost(\n",
    "                text=\"Not happy with Commonwealth Bank's latest fees increase üò†\",\n",
    "                created_at=datetime.strptime(start_date, '%Y-%m-%d') + timedelta(days=2),\n",
    "                platform=\"twitter\",\n",
    "                author=\"customer456\",\n",
    "                engagement_metrics={\"likes\": 23, \"retweets\": 8},\n",
    "                is_spam=False\n",
    "            ),\n",
    "            SocialPost(\n",
    "                text=\"CBA dividend announcement coming soon. Expecting good results!\",\n",
    "                created_at=datetime.strptime(start_date, '%Y-%m-%d') + timedelta(days=3),\n",
    "                platform=\"twitter\",\n",
    "                author=\"trader789\",\n",
    "                engagement_metrics={\"likes\": 67, \"retweets\": 15},\n",
    "                is_spam=False\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Filter for relevance and spam\n",
    "        relevant_posts = self._filter_relevant_posts(mock_posts)\n",
    "        clean_posts = [post for post in relevant_posts if not self._detect_spam(post)]\n",
    "        \n",
    "        return clean_posts\n",
    "\n",
    "print(\"‚úÖ SocialMediaClient class implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sentiment_data_collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Data Collector Implementation\n",
    "class SentimentDataCollector:\n",
    "    \"\"\"Orchestrates collection of sentiment data from multiple sources\"\"\"\n",
    "    \n",
    "    def __init__(self, config: SentimentConfig):\n",
    "        self.config = config\n",
    "        self.sentiment_analyzer = SentimentAnalyzer(config.sentiment_analyzer)\n",
    "        self.news_client = NewsAPIClient()\n",
    "        self.social_client = SocialMediaClient()\n",
    "    \n",
    "    def get_cached_data(self, symbol: str, date_range: tuple) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Check for cached sentiment data\"\"\"\n",
    "        start_date, end_date = date_range\n",
    "        cache_file = f\"{SENTIMENT_CACHE_DIR}/{symbol}_{start_date}_{end_date}_sentiment.csv\"\n",
    "        \n",
    "        if os.path.exists(cache_file):\n",
    "            # Check if cache is still valid\n",
    "            file_age = time.time() - os.path.getmtime(cache_file)\n",
    "            if file_age < (self.config.cache_duration_hours * 3600):\n",
    "                try:\n",
    "                    df = pd.read_csv(cache_file)\n",
    "                    df['Date'] = pd.to_datetime(df['Date'])\n",
    "                    logging.info(f\"Using cached sentiment data for {symbol}\")\n",
    "                    return df\n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"Error reading cache file: {e}\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def save_to_cache(self, data: pd.DataFrame, symbol: str, date_range: tuple) -> None:\n",
    "        \"\"\"Save sentiment data to cache\"\"\"\n",
    "        start_date, end_date = date_range\n",
    "        cache_file = f\"{SENTIMENT_CACHE_DIR}/{symbol}_{start_date}_{end_date}_sentiment.csv\"\n",
    "        \n",
    "        try:\n",
    "            data.to_csv(cache_file, index=False)\n",
    "            logging.info(f\"Sentiment data cached to {cache_file}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error saving to cache: {e}\")\n",
    "    \n",
    "    def _merge_sources(self, news_sentiment: pd.DataFrame, social_sentiment: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Combine news and social media sentiment\"\"\"\n",
    "        # Merge on date, using outer join to keep all dates\n",
    "        merged = pd.merge(news_sentiment, social_sentiment, on='Date', how='outer', suffixes=('_news', '_social'))\n",
    "        \n",
    "        # Calculate combined sentiment (weighted average)\n",
    "        news_weight = 0.6  # News typically more reliable\n",
    "        social_weight = 0.4\n",
    "        \n",
    "        merged['sentiment_compound'] = (\n",
    "            merged['sentiment_compound_news'].fillna(0) * news_weight +\n",
    "            merged['sentiment_compound_social'].fillna(0) * social_weight\n",
    "        )\n",
    "        \n",
    "        merged['sentiment_positive'] = (\n",
    "            merged['sentiment_positive_news'].fillna(0) * news_weight +\n",
    "            merged['sentiment_positive_social'].fillna(0) * social_weight\n",
    "        )\n",
    "        \n",
    "        merged['sentiment_negative'] = (\n",
    "            merged['sentiment_negative_news'].fillna(0) * news_weight +\n",
    "            merged['sentiment_negative_social'].fillna(0) * social_weight\n",
    "        )\n",
    "        \n",
    "        merged['sentiment_neutral'] = (\n",
    "            merged['sentiment_neutral_news'].fillna(1) * news_weight +\n",
    "            merged['sentiment_neutral_social'].fillna(1) * social_weight\n",
    "        )\n",
    "        \n",
    "        # Add volume metrics\n",
    "        merged['news_volume'] = merged['news_volume'].fillna(0)\n",
    "        merged['social_volume'] = merged['social_volume'].fillna(0)\n",
    "        merged['total_volume'] = merged['news_volume'] + merged['social_volume']\n",
    "        \n",
    "        # Select final columns\n",
    "        final_columns = ['Date', 'sentiment_compound', 'sentiment_positive', 'sentiment_negative', \n",
    "                        'sentiment_neutral', 'news_volume', 'social_volume', 'total_volume']\n",
    "        \n",
    "        return merged[final_columns]\n",
    "    \n",
    "    def _handle_missing_dates(self, sentiment_df: pd.DataFrame, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "        \"\"\"Fill gaps in sentiment data\"\"\"\n",
    "        # Create complete date range\n",
    "        date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "        complete_df = pd.DataFrame({'Date': date_range})\n",
    "        \n",
    "        # Merge with sentiment data\n",
    "        merged = pd.merge(complete_df, sentiment_df, on='Date', how='left')\n",
    "        \n",
    "        # Forward fill sentiment scores\n",
    "        sentiment_columns = ['sentiment_compound', 'sentiment_positive', 'sentiment_negative', 'sentiment_neutral']\n",
    "        for col in sentiment_columns:\n",
    "            merged[col] = merged[col].fillna(method='ffill').fillna(0.0)\n",
    "        \n",
    "        # Fill volume with 0\n",
    "        volume_columns = ['news_volume', 'social_volume', 'total_volume']\n",
    "        for col in volume_columns:\n",
    "            merged[col] = merged[col].fillna(0)\n",
    "        \n",
    "        return merged\n",
    "    \n",
    "    def collect_sentiment_data(self, symbol: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "        \"\"\"Main entry point for sentiment collection\"\"\"\n",
    "        if not self.config.enabled:\n",
    "            logging.info(\"Sentiment analysis disabled, returning neutral sentiment\")\n",
    "            return self._create_neutral_sentiment(start_date, end_date)\n",
    "        \n",
    "        date_range = (start_date, end_date)\n",
    "        \n",
    "        # Check cache first\n",
    "        cached_data = self.get_cached_data(symbol, date_range)\n",
    "        if cached_data is not None:\n",
    "            return cached_data\n",
    "        \n",
    "        logging.info(f\"Collecting sentiment data for {symbol} from {start_date} to {end_date}\")\n",
    "        \n",
    "        try:\n",
    "            # Collect news sentiment\n",
    "            news_sentiment = self._collect_news_sentiment(symbol, start_date, end_date)\n",
    "            \n",
    "            # Collect social media sentiment\n",
    "            social_sentiment = self._collect_social_sentiment(symbol, start_date, end_date)\n",
    "            \n",
    "            # Merge sources\n",
    "            combined_sentiment = self._merge_sources(news_sentiment, social_sentiment)\n",
    "            \n",
    "            # Handle missing dates\n",
    "            final_sentiment = self._handle_missing_dates(combined_sentiment, start_date, end_date)\n",
    "            \n",
    "            # Cache the results\n",
    "            self.save_to_cache(final_sentiment, symbol, date_range)\n",
    "            \n",
    "            return final_sentiment\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error collecting sentiment data: {e}\")\n",
    "            return self._create_neutral_sentiment(start_date, end_date)\n",
    "    \n",
    "    def _collect_news_sentiment(self, symbol: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "        \"\"\"Collect and analyze news sentiment\"\"\"\n",
    "        query = self.news_client._build_query(symbol)\n",
    "        articles = self.news_client.fetch_news(query, start_date, end_date)\n",
    "        \n",
    "        if not articles:\n",
    "            return self._create_empty_sentiment_df()\n",
    "        \n",
    "        # Analyze sentiment for each article\n",
    "        daily_sentiment = {}\n",
    "        \n",
    "        for article in articles:\n",
    "            date_key = article.published_at.date()\n",
    "            text = f\"{article.title} {article.content}\"\n",
    "            sentiment = self.sentiment_analyzer.analyze_text(text)\n",
    "            \n",
    "            if date_key not in daily_sentiment:\n",
    "                daily_sentiment[date_key] = []\n",
    "            \n",
    "            daily_sentiment[date_key].append(sentiment)\n",
    "        \n",
    "        # Aggregate daily sentiment\n",
    "        sentiment_data = []\n",
    "        for date, sentiments in daily_sentiment.items():\n",
    "            avg_compound = np.mean([s.compound for s in sentiments])\n",
    "            avg_positive = np.mean([s.positive for s in sentiments])\n",
    "            avg_negative = np.mean([s.negative for s in sentiments])\n",
    "            avg_neutral = np.mean([s.neutral for s in sentiments])\n",
    "            \n",
    "            sentiment_data.append({\n",
    "                'Date': pd.to_datetime(date),\n",
    "                'sentiment_compound_news': avg_compound,\n",
    "                'sentiment_positive_news': avg_positive,\n",
    "                'sentiment_negative_news': avg_negative,\n",
    "                'sentiment_neutral_news': avg_neutral,\n",
    "                'news_volume': len(sentiments)\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(sentiment_data)\n",
    "    \n",
    "    def _collect_social_sentiment(self, symbol: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "        \"\"\"Collect and analyze social media sentiment\"\"\"\n",
    "        query = symbol\n",
    "        posts = self.social_client.fetch_posts(query, start_date, end_date)\n",
    "        \n",
    "        if not posts:\n",
    "            return self._create_empty_sentiment_df()\n",
    "        \n",
    "        # Analyze sentiment for each post\n",
    "        daily_sentiment = {}\n",
    "        \n",
    "        for post in posts:\n",
    "            date_key = post.created_at.date()\n",
    "            sentiment = self.sentiment_analyzer.analyze_text(post.text)\n",
    "            \n",
    "            if date_key not in daily_sentiment:\n",
    "                daily_sentiment[date_key] = []\n",
    "            \n",
    "            daily_sentiment[date_key].append(sentiment)\n",
    "        \n",
    "        # Aggregate daily sentiment\n",
    "        sentiment_data = []\n",
    "        for date, sentiments in daily_sentiment.items():\n",
    "            avg_compound = np.mean([s.compound for s in sentiments])\n",
    "            avg_positive = np.mean([s.positive for s in sentiments])\n",
    "            avg_negative = np.mean([s.negative for s in sentiments])\n",
    "            avg_neutral = np.mean([s.neutral for s in sentiments])\n",
    "            \n",
    "            sentiment_data.append({\n",
    "                'Date': pd.to_datetime(date),\n",
    "                'sentiment_compound_social': avg_compound,\n",
    "                'sentiment_positive_social': avg_positive,\n",
    "                'sentiment_negative_social': avg_negative,\n",
    "                'sentiment_neutral_social': avg_neutral,\n",
    "                'social_volume': len(sentiments)\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(sentiment_data)\n",
    "    \n",
    "    def _create_empty_sentiment_df(self) -> pd.DataFrame:\n",
    "        \"\"\"Create empty sentiment dataframe\"\"\"\n",
    "        return pd.DataFrame(columns=['Date', 'sentiment_compound', 'sentiment_positive', \n",
    "                                   'sentiment_negative', 'sentiment_neutral', 'news_volume', \n",
    "                                   'social_volume', 'total_volume'])\n",
    "    \n",
    "    def _create_neutral_sentiment(self, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "        \"\"\"Create neutral sentiment for date range\"\"\"\n",
    "        date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'Date': date_range,\n",
    "            'sentiment_compound': 0.0,\n",
    "            'sentiment_positive': 0.0,\n",
    "            'sentiment_negative': 0.0,\n",
    "            'sentiment_neutral': 1.0,\n",
    "            'news_volume': 0,\n",
    "            'social_volume': 0,\n",
    "            'total_volume': 0\n",
    "        })\n",
    "\n",
    "print(\"‚úÖ SentimentDataCollector class implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c9b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the necessary directories exist\n",
    "DATA_DIR = \"data\"  # Directory to save the data\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "    \n",
    "# Define constants outside the loop\n",
    "COMPANY = 'CBA.AX'\n",
    "DEFAULT_TRAIN_START = '2020-01-01'\n",
    "DEFAULT_TRAIN_END = '2023-01-01'\n",
    "while True:\n",
    "    try:\n",
    "        # Get training start date\n",
    "        TRAIN_START = input(f\"Enter training start date (YYYY-MM-DD) or press Enter for default '{DEFAULT_TRAIN_START}': \")\n",
    "        if not TRAIN_START.strip():\n",
    "            TRAIN_START = DEFAULT_TRAIN_START\n",
    "        \n",
    "        # Get training end date\n",
    "        TRAIN_END = input(f\"Enter training end date (YYYY-MM-DD) or press Enter for default '{DEFAULT_TRAIN_END}': \")\n",
    "        if not TRAIN_END.strip():\n",
    "            TRAIN_END = DEFAULT_TRAIN_END\n",
    "        \n",
    "        # Validate date format\n",
    "        start_date = dt.datetime.strptime(TRAIN_START, '%Y-%m-%d')\n",
    "        end_date = dt.datetime.strptime(TRAIN_END, '%Y-%m-%d')\n",
    "        \n",
    "        # Validate date range\n",
    "        if start_date >= end_date:\n",
    "            print(\"Error: Training end date must be after training start date.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Using training period: {TRAIN_START} to {TRAIN_END}\")\n",
    "        break  # Exit the loop if everything is valid\n",
    "    \n",
    "    except ValueError:\n",
    "        print(\"Invalid date format. Please use YYYY-MM-DD format.\")\n",
    "        print(f\"Using default values: {DEFAULT_TRAIN_START} to {DEFAULT_TRAIN_END}\")\n",
    "        TRAIN_START = DEFAULT_TRAIN_START\n",
    "        TRAIN_END = DEFAULT_TRAIN_END\n",
    "        break  # Or continue to ask again by removing this line\n",
    "\n",
    "# Get the data for the stock AAPL\n",
    "data = yf.download(COMPANY,TRAIN_START,TRAIN_END)\n",
    "data_filename = f\"{DATA_DIR}/{COMPANY}_data.csv\"\n",
    "\n",
    "\n",
    "# If it does not exist, save the data to the file\n",
    "print(f\"Saving data to {data_filename}\")\n",
    "data.to_csv(data_filename)\n",
    "print(f\"Data saved to {data_filename}\")\n",
    "\n",
    "df = pd.read_csv(data_filename, skiprows=[1,2])\n",
    "\n",
    "# Preprocess the data\n",
    "# Check for missing values and handle them properly\n",
    "print(\"\\nMissing values check:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle missing values with forward fill or interpolation\n",
    "df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# The columns actually contain: Date, Price, Close, High, Low, Volume\n",
    "df.columns = ['Date', 'Open', 'Close', 'High', 'Low', 'Volume']\n",
    "\n",
    "# Add after your feature columns definition\n",
    "def create_technical_indicators(df):\n",
    "    \"\"\"Add technical indicators as features\"\"\"\n",
    "    # Moving averages\n",
    "    df['MA_5'] = df['Close'].rolling(window=5).mean()\n",
    "    df['MA_20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['MA_50'] = df['Close'].rolling(window=50).mean()\n",
    "    \n",
    "    # RSI\n",
    "    delta = df['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    df['BB_upper'] = df['MA_20'] + (df['Close'].rolling(window=20).std() * 2)\n",
    "    df['BB_lower'] = df['MA_20'] - (df['Close'].rolling(window=20).std() * 2)\n",
    "    \n",
    "    # MACD\n",
    "    exp1 = df['Close'].ewm(span=12).mean()\n",
    "    exp2 = df['Close'].ewm(span=26).mean()\n",
    "    df['MACD'] = exp1 - exp2\n",
    "    \n",
    "    # Volatility\n",
    "    df['Volatility'] = df['Close'].rolling(window=20).std()\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "# Sentiment Feature Engineering\n",
    "class SentimentFeatureEngineer:\n",
    "    \"\"\"Converts raw sentiment scores into ML-ready features\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rolling_windows = [3, 7, 14]\n",
    "    \n",
    "    def create_sentiment_features(self, sentiment_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create comprehensive sentiment features\"\"\"\n",
    "        df = sentiment_df.copy()\n",
    "        \n",
    "        # Calculate rolling sentiment averages\n",
    "        df = self._calculate_rolling_sentiment(df, self.rolling_windows)\n",
    "        \n",
    "        # Create sentiment momentum features\n",
    "        df = self._create_sentiment_momentum(df)\n",
    "        \n",
    "        # Create sentiment volatility features\n",
    "        df = self._create_sentiment_volatility(df)\n",
    "        \n",
    "        return df.dropna()\n",
    "    \n",
    "    def _calculate_rolling_sentiment(self, df: pd.DataFrame, windows: List[int]) -> pd.DataFrame:\n",
    "        \"\"\"Calculate rolling averages for sentiment scores\"\"\"\n",
    "        for window in windows:\n",
    "            df[f'sentiment_compound_ma_{window}'] = df['sentiment_compound'].rolling(window=window).mean()\n",
    "            df[f'sentiment_positive_ma_{window}'] = df['sentiment_positive'].rolling(window=window).mean()\n",
    "            df[f'sentiment_negative_ma_{window}'] = df['sentiment_negative'].rolling(window=window).mean()\n",
    "            df[f'sentiment_volume_ma_{window}'] = df['total_volume'].rolling(window=window).mean()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _create_sentiment_momentum(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create sentiment momentum (rate of change) features\"\"\"\n",
    "        # 1-day momentum\n",
    "        df['sentiment_momentum_1d'] = df['sentiment_compound'].diff(1)\n",
    "        \n",
    "        # 3-day momentum\n",
    "        df['sentiment_momentum_3d'] = df['sentiment_compound'].diff(3)\n",
    "        \n",
    "        # 7-day momentum\n",
    "        df['sentiment_momentum_7d'] = df['sentiment_compound'].diff(7)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _create_sentiment_volatility(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create sentiment volatility features\"\"\"\n",
    "        # Rolling standard deviation of sentiment\n",
    "        df['sentiment_volatility_7d'] = df['sentiment_compound'].rolling(window=7).std()\n",
    "        df['sentiment_volatility_14d'] = df['sentiment_compound'].rolling(window=14).std()\n",
    "        \n",
    "        # Volume volatility\n",
    "        df['volume_volatility_7d'] = df['total_volume'].rolling(window=7).std()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def align_with_stock_data(self, sentiment_df: pd.DataFrame, stock_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Align sentiment data with stock data by date\"\"\"\n",
    "        # Ensure both dataframes have Date column as datetime\n",
    "        sentiment_df['Date'] = pd.to_datetime(sentiment_df['Date'])\n",
    "        stock_df['Date'] = pd.to_datetime(stock_df['Date'])\n",
    "        \n",
    "        # Merge on date (inner join to keep only matching dates)\n",
    "        merged = pd.merge(stock_df, sentiment_df, on='Date', how='left')\n",
    "        \n",
    "        # Forward fill missing sentiment values\n",
    "        sentiment_columns = [col for col in merged.columns if 'sentiment' in col or 'volume' in col]\n",
    "        for col in sentiment_columns:\n",
    "            merged[col] = merged[col].fillna(method='ffill').fillna(0.0)\n",
    "        \n",
    "        return merged\n",
    "\n",
    "# Enhanced technical indicators function with sentiment integration\n",
    "def create_enhanced_technical_indicators(df, sentiment_data=None, enable_sentiment=True):\n",
    "    \"\"\"Create technical indicators with optional sentiment features\"\"\"\n",
    "    # Create base technical indicators\n",
    "    df = create_technical_indicators(df)\n",
    "    \n",
    "    # Add sentiment features if enabled and data is available\n",
    "    if enable_sentiment and sentiment_data is not None:\n",
    "        sentiment_engineer = SentimentFeatureEngineer()\n",
    "        \n",
    "        # Create sentiment features\n",
    "        enhanced_sentiment = sentiment_engineer.create_sentiment_features(sentiment_data)\n",
    "        \n",
    "        # Align with stock data\n",
    "        df = sentiment_engineer.align_with_stock_data(enhanced_sentiment, df)\n",
    "        \n",
    "        print(f\"‚úÖ Enhanced features with sentiment analysis. Shape: {df.shape}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Base technical indicators only. Shape: {df.shape}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Ask user if they want to enable sentiment analysis\n",
    "enable_sentiment = input(\"Enable sentiment analysis? (y/n, default=n): \").strip().lower()\n",
    "enable_sentiment = enable_sentiment in ['y', 'yes', '1', 'true']\n",
    "\n",
    "sentiment_data = None\n",
    "if enable_sentiment:\n",
    "    print(\"\\nüîç Collecting sentiment data...\")\n",
    "    try:\n",
    "        # Initialize sentiment configuration\n",
    "        sentiment_config = SentimentConfig(\n",
    "            enabled=True,\n",
    "            news_sources=['newsapi'],\n",
    "            social_platforms=['twitter'],\n",
    "            sentiment_analyzer='vader',\n",
    "            cache_duration_hours=24,\n",
    "            max_articles_per_day=50,\n",
    "            max_posts_per_day=100\n",
    "        )\n",
    "        \n",
    "        # Initialize sentiment data collector\n",
    "        sentiment_collector = SentimentDataCollector(sentiment_config)\n",
    "        \n",
    "        # Collect sentiment data for the same date range as stock data\n",
    "        sentiment_data = sentiment_collector.collect_sentiment_data(\n",
    "            symbol=COMPANY,\n",
    "            start_date=TRAIN_START,\n",
    "            end_date=TRAIN_END\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Sentiment data collected. Shape: {sentiment_data.shape}\")\n",
    "        print(\"\\nSentiment Data Sample:\")\n",
    "        print(sentiment_data.head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error collecting sentiment data: {e}\")\n",
    "        print(\"Continuing with technical indicators only...\")\n",
    "        enable_sentiment = False\n",
    "\n",
    "# Create enhanced features with optional sentiment\n",
    "df = create_enhanced_technical_indicators(df, sentiment_data, enable_sentiment)\n",
    "    \n",
    "# Save new cleaned data to a CSV file\n",
    "cleaned_data_filename = f\"{DATA_DIR}/{COMPANY}_cleaned_data.csv\"\n",
    "df.to_csv(cleaned_data_filename, index=False)\n",
    "print(f\"Cleaned data saved to {cleaned_data_filename}\")\n",
    "\n",
    "# Check few rows of the cleaned data\n",
    "print(\"Cleaned Data Sample:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee95d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "# Define splitting functions\n",
    "def split_by_ratio_sequential(df, test_size_ratio):\n",
    "    \"\"\"Split data sequentially based on a ratio.\"\"\"\n",
    "    split_index = int(len(df) * (1 - test_size_ratio))\n",
    "    train_data = df.iloc[:split_index]\n",
    "    test_data = df.iloc[split_index:]\n",
    "    return train_data, test_data\n",
    "\n",
    "def split_by_date(df, cutoff_date):\n",
    "    \"\"\"Split data based on a specific cutoff date.\"\"\"\n",
    "    cutoff_date = pd.to_datetime(cutoff_date)\n",
    "    train_data = df[df['Date'] < cutoff_date]\n",
    "    test_data = df[df['Date'] >= cutoff_date]\n",
    "    return train_data, test_data\n",
    "\n",
    "def split_by_ratio_random(df, test_size_ratio):\n",
    "    \"\"\"Split data randomly based on a ratio.\"\"\"\n",
    "    train_data, test_data = train_test_split(df, test_size=test_size_ratio, random_state=42, shuffle=True)\n",
    "    return train_data, test_data\n",
    "\n",
    "# Load cleaned data\n",
    "df = pd.read_csv(cleaned_data_filename)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Get user input for splitting method\n",
    "while True:\n",
    "    print(\"\\nChoose a data splitting method:\")\n",
    "    print(\"1. Sequential split by ratio\")\n",
    "    print(\"2. Split by date\")\n",
    "    print(\"3. Random split by ratio\")\n",
    "    choice = input(\"Enter your choice (1/2/3): \").strip()\n",
    "    \n",
    "    if choice == '1':\n",
    "        ratio = input(\"Enter test size ratio (e.g., 0.2 for 20%): \").strip()\n",
    "        test_ratio = float(ratio) if ratio and 0 < float(ratio) < 1 else 0.2\n",
    "        train_data, test_data = split_by_ratio_sequential(df, test_ratio)\n",
    "        print(f\"Data split sequentially with {test_ratio*100}% for testing.\")\n",
    "        break\n",
    "    elif choice == '2':\n",
    "        cutoff_date = input(\"Enter cutoff date (YYYY-MM-DD): \").strip()\n",
    "        train_data, test_data = split_by_date(df, cutoff_date)\n",
    "        print(f\"Data split by date with cutoff at {cutoff_date}.\")\n",
    "        break\n",
    "    elif choice == '3':\n",
    "        ratio = input(\"Enter test size ratio (e.g., 0.2 for 20%): \").strip()\n",
    "        test_ratio = float(ratio) if ratio and 0 < float(ratio) < 1 else 0.2\n",
    "        train_data, test_data = split_by_ratio_random(df, test_ratio)\n",
    "        print(f\"Data split randomly with {test_ratio*100}% for testing.\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid choice. Please enter 1, 2, or 3.\")\n",
    "\n",
    "# Print shapes\n",
    "print(f\"Train data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a15c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Scaling\n",
    "# Define feature columns\n",
    "feature_columns = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "\n",
    "# Initialize dictionaries for scaled data\n",
    "scalers = {}\n",
    "scaled_train_data = train_data.copy()\n",
    "scaled_test_data = test_data.copy()\n",
    "\n",
    "# Scale features\n",
    "print(\"Scaling feature columns...\")\n",
    "for column in feature_columns:\n",
    "    if column in train_data.columns:\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_train_data[column] = scaler.fit_transform(train_data[[column]])\n",
    "        scaled_test_data[column] = scaler.transform(test_data[[column]])\n",
    "        scalers[column] = scaler\n",
    "        print(f\"Scaled column: {column}\")\n",
    "        print(f\"  Original range: [{train_data[column].min():.4f}, {train_data[column].max():.4f}]\")\n",
    "        print(f\"  Scaled range: [{scaled_train_data[column].min():.4f}, {scaled_train_data[column].max():.4f}]\")\n",
    "\n",
    "# Save scalers\n",
    "scalers_filename = f\"{DATA_DIR}/{COMPANY}_scalers.pkl\"\n",
    "with open(scalers_filename, 'wb') as f:\n",
    "    pickle.dump(scalers, f)\n",
    "print(f\"\\nScalers saved to {scalers_filename}\")\n",
    "\n",
    "# Scaling summary\n",
    "print(f\"\\nScaling Summary:\")\n",
    "print(f\"Number of features scaled: {len(scalers)}\")\n",
    "print(f\"Scaled features: {list(scalers.keys())}\")\n",
    "print(f\"Train data shape after scaling: {scaled_train_data.shape}\")\n",
    "print(f\"Test data shape after scaling: {scaled_test_data.shape}\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nSample of scaled training data:\")\n",
    "print(scaled_train_data.head())\n",
    "print(\"\\nSample of scaled test data:\")\n",
    "print(scaled_test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4867cdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of days to look back to base the prediction\n",
    "PREDICTION_DAYS = 60 # Original\n",
    "\n",
    "# --- Prerequisite Check ---\n",
    "# Ensure the necessary scaled data from the previous steps is available.\n",
    "print(\"Checking for prerequisite data...\")\n",
    "scaled_train_data\n",
    "scaled_test_data\n",
    "print(\"‚úÖ Found 'scaled_train_data' and 'scaled_test_data'.\")\n",
    "\n",
    "# --- Data Preparation for Models ---\n",
    "# This part of the code prepares the data in the sequence format required by recurrent models.\n",
    "# Correct feature columns based on the cleaning step. \n",
    "# The available numeric columns after cleaning are ['Price', 'Close', 'High', 'Low', 'Volume']\n",
    "# We will predict 'Close' price, and use others as features.\n",
    "# Let's define the columns we will use for training. 'Close' must be the first one.\n",
    "feature_columns = ['Close', 'Open', 'High', 'Low', 'Volume']\n",
    "\n",
    "# Select and convert data to numpy arrays\n",
    "train_values = scaled_train_data[feature_columns].values\n",
    "test_values = scaled_test_data[feature_columns].values\n",
    "\n",
    "# --- NEW: Define the prediction horizon ---\n",
    "PREDICTION_HORIZON = 30 # Number of future days to predict at once\n",
    "\n",
    "# --- MODIFIED: Function to create sequences for Direct Multi-step Forecasting ---\n",
    "def create_sequences_direct(data, look_back, horizon):\n",
    "    \"\"\"\n",
    "    Creates sequences and corresponding multi-step labels for direct forecasting.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    # The loop must end early to ensure there are 'horizon' days left for the label\n",
    "    for i in range(look_back, len(data) - horizon):\n",
    "        X.append(data[i-look_back:i, :]) # Input: Sequence of 'look_back' days\n",
    "        y.append(data[i:i+horizon, 0])   # Target: Sequence of the next 'horizon' 'Close' prices\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create training and testing sequences using the new function\n",
    "X_train, y_train = create_sequences_direct(train_values, PREDICTION_DAYS, PREDICTION_HORIZON)\n",
    "X_test, y_test = create_sequences_direct(test_values, PREDICTION_DAYS, PREDICTION_HORIZON)\n",
    "\n",
    "\n",
    "print(\"\\n--- Data Shapes for Direct Multi-step Modeling ---\")\n",
    "print(f\"X_train shape: {X_train.shape}\") # Will be (samples, 60, 5)\n",
    "print(f\"y_train shape: {y_train.shape}\") # Will now be (samples, 30)\n",
    "print(f\"X_test shape: {X_test.shape}\")  # Will be (samples, 60, 5)\n",
    "print(f\"y_test shape: {y_test.shape}\")  # Will now be (samples, 30)\n",
    "print(\"----------------------------------------------------\")\n",
    "\n",
    "# Add after your data preparation\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "def time_series_cross_validation(X, y, model_builder, n_splits=5):\n",
    "    \"\"\"Perform time series cross-validation\"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
    "        print(f\"Training fold {fold + 1}/{n_splits}\")\n",
    "        \n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "        \n",
    "        model = model_builder()\n",
    "        model.fit(X_train_fold, y_train_fold, epochs=50, batch_size=32, verbose=0)\n",
    "        \n",
    "        val_pred = model.predict(X_val_fold, verbose=0)\n",
    "        val_mae = mean_absolute_error(y_val_fold, val_pred)\n",
    "        scores.append(val_mae)\n",
    "        \n",
    "        print(f\"Fold {fold + 1} MAE: {val_mae:.6f}\")\n",
    "    \n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "# Function to create the dataset with lookback\n",
    "def create_dataset(data, look_back=1):\n",
    "    \"\"\"Create dataset with lookback feature\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:(i + look_back), :])\n",
    "        y.append(data[i + look_back, 0])  # Assuming the first column is the target\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Build model function\n",
    "def build_improved_model(input_shape, model_type='lstm', use_attention=False):\n",
    "    \"\"\"Build improved model with better architecture\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    \n",
    "    if model_type.lower() == 'lstm':\n",
    "        model.add(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "        model.add(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "        model.add(LSTM(32, return_sequences=False, dropout=0.2, recurrent_dropout=0.2))\n",
    "    elif model_type.lower() == 'gru':\n",
    "        model.add(GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "        model.add(GRU(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "        model.add(GRU(32, return_sequences=False, dropout=0.2, recurrent_dropout=0.2))\n",
    "    elif model_type.lower() == 'rnn':\n",
    "        model.add(SimpleRNN(128, return_sequences=True, dropout=0.2))\n",
    "        model.add(SimpleRNN(64, return_sequences=True, dropout=0.2))\n",
    "        model.add(SimpleRNN(32, return_sequences=False, dropout=0.2))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type. Choose 'lstm', 'gru', or 'rnn'.\")\n",
    "    \n",
    "    # Add batch normalization\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # Use better optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "    model.compile(optimizer=optimizer, loss='huber', metrics=['mae', 'mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b8bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model frame\n",
    "def build_model(input_shape, layers_config):\n",
    "    \"\"\"Build model based on configuration\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    \n",
    "    for layer_config in layers_config:\n",
    "        if layer_config['type'] == 'lstm':\n",
    "            model.add(LSTM(\n",
    "                layer_config['units'],\n",
    "                return_sequences=layer_config.get('return_sequences', False),\n",
    "                name=layer_config.get('name')\n",
    "            ))\n",
    "        elif layer_config['type'] == 'gru':\n",
    "            model.add(GRU(\n",
    "                layer_config['units'],\n",
    "                return_sequences=layer_config.get('return_sequences', False),\n",
    "                name=layer_config.get('name')\n",
    "            ))\n",
    "        elif layer_config['type'] == 'rnn':\n",
    "            model.add(SimpleRNN(\n",
    "                layer_config['units'],\n",
    "                return_sequences=layer_config.get('return_sequences', False),\n",
    "                name=layer_config.get('name')\n",
    "            ))\n",
    "        elif layer_config['type'] == 'dropout':\n",
    "            model.add(Dropout(layer_config['rate']))\n",
    "        elif layer_config['type'] == 'batch_normalization':\n",
    "            model.add(BatchNormalization())\n",
    "        elif layer_config['type'] == 'dense':\n",
    "            model.add(Dense(\n",
    "                layer_config['units'],\n",
    "                activation=layer_config.get('activation', 'linear'),\n",
    "                name=layer_config.get('name')\n",
    "            ))\n",
    "        \n",
    "    model.compile(optimizer='adam', loss='huber', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4862949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LSTM Model\n",
    "print(\"===== Training LSTM Model (Direct Multi-step) =====\")\n",
    "lstm_layers = [\n",
    "    {'type': 'lstm', 'units': 80, 'return_sequences': True, 'name': 'lstm_1'},\n",
    "    {'type': 'dropout', 'rate': 0.2},\n",
    "    {'type': 'lstm', 'units': 40, 'return_sequences': False, 'name': 'lstm_2'},\n",
    "    {'type': 'dropout', 'rate': 0.2},\n",
    "    {'type': 'dense', 'units': 20, 'activation': 'relu', 'name': 'dense_19'},\n",
    "    {'type': 'dense', 'units': PREDICTION_HORIZON, 'activation': 'linear', 'name': 'output_layer'}\n",
    "]\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "model_filename = os.path.join(MODEL_DIR, f\"{COMPANY}_lstm_model.keras\")\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "lstm_model = build_model(input_shape, lstm_layers)\n",
    "history_lstm = lstm_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint(model_filename, save_best_only=True, monitor='val_loss')\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, mae = lstm_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"\\n--- LSTM Model Evaluation ---\")\n",
    "print(f\"Test Loss (Huber): {loss:.6f}\")\n",
    "print(f\"Test Mean Absolute Error (MAE): {mae:.6f}\")\n",
    "print(f\"Model saved to: {model_filename}\")\n",
    "print(\"==============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8e33e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GRU Model\n",
    "print(\"===== Training GRU Model =====\")\n",
    "gru_layers = [\n",
    "    {'type': 'gru', 'units': 100, 'return_sequences': True, 'name': 'gru_1'},\n",
    "    {'type': 'dropout', 'rate': 0.2},\n",
    "    {'type': 'gru', 'units': 50, 'return_sequences': False, 'name': 'gru_2'},\n",
    "    {'type': 'dropout', 'rate': 0.2},\n",
    "    {'type': 'dense', 'units': 25, 'activation': 'relu', 'name': 'dense_100'},\n",
    "    {'type': 'dense', 'units': PREDICTION_HORIZON, 'activation': 'linear', 'name': 'output_layer_gru'}\n",
    "    \n",
    "]\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "model_filename = os.path.join(MODEL_DIR, f\"{COMPANY}_gru_model.keras\")\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "gru_model = build_model(input_shape, gru_layers)\n",
    "history_gru = gru_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint(model_filename, save_best_only=True, monitor='val_loss')\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, mae = gru_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"\\n--- GRU Model Evaluation ---\")\n",
    "print(f\"Test Loss (Huber): {loss:.6f}\")\n",
    "print(f\"Test Mean Absolute Error (MAE): {mae:.6f}\")\n",
    "print(f\"Model saved to: {model_filename}\")\n",
    "print(\"=============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6a5f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced RNN Model with Better Architecture\n",
    "print(\"===== Training Optimized RNN Model =====\")\n",
    "\n",
    "rnn_layers = [\n",
    "    # Use fewer, larger layers with better regularization\n",
    "    {'type': 'rnn', 'units': 128, 'return_sequences': True, 'name': 'rnn_1'},\n",
    "    {'type': 'batch_normalization'},  \n",
    "    {'type': 'dropout', 'rate': 0.3},\n",
    "    \n",
    "    {'type': 'rnn', 'units': 64, 'return_sequences': False, 'name': 'rnn_2'},\n",
    "    {'type': 'batch_normalization'},\n",
    "    {'type': 'dropout', 'rate': 0.2},\n",
    "    \n",
    "    # Simpler dense layers\n",
    "    {'type': 'dense', 'units': 32, 'activation': 'relu', 'name': 'dense_1'},\n",
    "    {'type': 'dropout', 'rate': 0.1},  \n",
    "    {'type': 'dense', 'units': PREDICTION_HORIZON, 'activation': 'linear', 'name': 'output_layer_rnn'}\n",
    "]\n",
    "\n",
    "# Better training configuration\n",
    "epochs = 50  # More epochs with early stopping\n",
    "batch_size = 16  # Smaller batch size for better gradients\n",
    "model_filename = os.path.join(MODEL_DIR, f\"{COMPANY}_rnn_model.keras\")\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Build with improved compilation\n",
    "rnn_model = build_model(input_shape, rnn_layers)\n",
    "\n",
    "# Use Huber loss (more robust to outliers) and better optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0005,  # Lower learning rate\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-7\n",
    ")\n",
    "rnn_model.compile(optimizer=optimizer, loss='huber', metrics=['mae'])\n",
    "\n",
    "# Enhanced callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=20, \n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        model_filename, \n",
    "        save_best_only=True, \n",
    "        monitor='val_loss',\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history_rnn = rnn_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, mae = rnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\n--- Optimized RNN Model Evaluation ---\")\n",
    "print(f\"Test Loss (Huber): {loss:.6f}\")\n",
    "print(f\"Test Mean Absolute Error (MAE): {mae:.6f}\")\n",
    "print(f\"Model saved to: {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c36f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===== Training Random Forest Model =====\")\n",
    "\n",
    "# Feature engineering for Random Forest\n",
    "def create_rf_features(X_data, y_data):\n",
    "    \"\"\"Create features for Random Forest\"\"\"\n",
    "    features = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(len(X_data)):\n",
    "        sample = X_data[i]  # Shape: (60, 5)\n",
    "        \n",
    "        # Statistical features across time windows\n",
    "        recent_close = sample[:, 0]  # Close prices\n",
    "        recent_volume = sample[:, 4]  # Volume\n",
    "        \n",
    "        # --- Safely calculate features that involve division ---\n",
    "        # Calculate 20-day return, handle division by zero\n",
    "        close_20_day_ago = recent_close[-20]\n",
    "        return_20_day = (recent_close[-1] - close_20_day_ago) / close_20_day_ago if close_20_day_ago != 0 else 0\n",
    "        \n",
    "        # Calculate volume ratio, handle division by zero\n",
    "        mean_volume_10_day = np.mean(recent_volume[-10:])\n",
    "        volume_ratio = recent_volume[-1] / mean_volume_10_day if mean_volume_10_day != 0 else 1.0\n",
    "\n",
    "        feature_vector = [\n",
    "            # Price statistics\n",
    "            np.mean(recent_close[-5:]),    # 5-day avg\n",
    "            np.mean(recent_close[-10:]),   # 10-day avg\n",
    "            np.mean(recent_close[-20:]),   # 20-day avg\n",
    "            np.std(recent_close[-10:]),    # Volatility\n",
    "            np.max(recent_close) - np.min(recent_close),  # Price range\n",
    "            \n",
    "            # Trend features\n",
    "            recent_close[-1] - recent_close[-5],   # 5-day change\n",
    "            recent_close[-1] - recent_close[-10],  # 10-day change\n",
    "            return_20_day,  # Safely calculated 20-day return\n",
    "            \n",
    "            # Volume features\n",
    "            np.mean(recent_volume[-5:]),   # Avg volume\n",
    "            volume_ratio,  # Safely calculated volume ratio\n",
    "            \n",
    "            # Technical indicators\n",
    "            np.mean(sample[-5:, 1]),  # Recent high avg\n",
    "            np.mean(sample[-5:, 2]),  # Recent low avg\n",
    "            \n",
    "            # Momentum\n",
    "            np.sum(np.diff(recent_close[-10:]) > 0),  # Up days count\n",
    "        ]\n",
    "        \n",
    "        features.append(feature_vector)\n",
    "        targets.append(y_data[i])\n",
    "    \n",
    "    # Replace any potential lingering NaN/inf values just in case\n",
    "    features_array = np.array(features)\n",
    "    features_array[~np.isfinite(features_array)] = 0\n",
    "    \n",
    "    return features_array, np.array(targets)\n",
    "\n",
    "# Create features\n",
    "X_train_rf, y_train_rf = create_rf_features(X_train, y_train)\n",
    "X_test_rf, y_test_rf = create_rf_features(X_test, y_test)\n",
    "\n",
    "print(f\"RF training data shape: {X_train_rf.shape}\")\n",
    "\n",
    "# Random Forest configuration\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "rf_model.fit(X_train_rf, y_train_rf)\n",
    "\n",
    "# Save model\n",
    "model_filename = os.path.join(MODEL_DIR, f\"{COMPANY}_rf_model.pkl\")\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "print(f\"Model saved to: {model_filename}\")\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "rf_predictions = rf_model.predict(X_test_rf)\n",
    "rf_mae = mean_absolute_error(y_test_rf, rf_predictions)\n",
    "\n",
    "print(\"\\n--- Random Forest Model Evaluation ---\")\n",
    "print(f\"Test Mean Absolute Error (MAE): {rf_mae:.6f}\")\n",
    "print(\"==================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings from statsmodels to keep the output clean during the search\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "def run_arima_grid_search(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Performs ARIMA analysis using a manual grid search with statsmodels.\n",
    "    - Checks for stationarity and models returns if they are stationary.\n",
    "    - Iterates through p, d, q combinations to find the best model based on AIC.\n",
    "    - Trains the best model, makes predictions, and converts them back to prices.\n",
    "    \"\"\"\n",
    "    print(\"\\n===== Running Manual ARIMA Grid Search Analysis (using statsmodels) =====\")\n",
    "    \n",
    "    # It's often best to model returns rather than prices directly\n",
    "    train_returns = train_df['Close'].pct_change().dropna()\n",
    "    \n",
    "    # Check for stationarity of returns\n",
    "    adf_test = adfuller(train_returns)\n",
    "    print(f\"ADF test on price returns p-value: {adf_test[1]:.6f}\")\n",
    "    \n",
    "    if adf_test[1] > 0.05:\n",
    "        print(\"‚ö†Ô∏è Returns are not stationary. ARIMA may perform poorly. Using prices instead.\")\n",
    "        train_target = train_df['Close']\n",
    "        # For non-stationary data, d is likely to be 1 or 2.\n",
    "        d_range = range(1, 3) \n",
    "    else:\n",
    "        print(\"‚úÖ Returns are stationary. Modeling returns.\")\n",
    "        train_target = train_returns\n",
    "        # For stationary data, d is likely 0.\n",
    "        d_range = range(0, 1)\n",
    "\n",
    "    # Define the p, d, q parameters to take any value between 0 and 2\n",
    "    p_range = q_range = range(0, 3)\n",
    "    pdq_combinations = list(itertools.product(p_range, d_range, q_range))\n",
    "\n",
    "    print(f\"Searching for optimal ARIMA parameters from {len(pdq_combinations)} combinations...\")\n",
    "    \n",
    "    best_aic = float(\"inf\")\n",
    "    best_pdq = None\n",
    "    best_model = None\n",
    "\n",
    "    for params in pdq_combinations:\n",
    "        try:\n",
    "            model = ARIMA(train_target, order=params).fit()\n",
    "            if model.aic < best_aic:\n",
    "                best_aic = model.aic\n",
    "                best_pdq = params\n",
    "                best_model = model\n",
    "        except Exception as e:\n",
    "            # Some parameter combinations may be invalid\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n‚úÖ Optimal ARIMA model found: order={best_pdq} with AIC={best_aic:.2f}\")\n",
    "    \n",
    "    # Generate forecasts\n",
    "    n_periods = len(test_df)\n",
    "    forecasts = best_model.forecast(steps=n_periods)\n",
    "    \n",
    "    # Convert forecasts back to prices if we modeled returns\n",
    "    if adf_test[1] <= 0.05:\n",
    "        print(\"Converting return forecasts back to prices...\")\n",
    "        last_price = train_df['Close'].iloc[-1]\n",
    "        price_predictions = []\n",
    "        current_price = last_price\n",
    "        for ret in forecasts:\n",
    "            current_price *= (1 + ret)\n",
    "            price_predictions.append(current_price)\n",
    "        price_predictions = np.array(price_predictions)\n",
    "    else: # If we modeled prices directly\n",
    "        price_predictions = forecasts.values\n",
    "\n",
    "    return price_predictions, best_model\n",
    "\n",
    "# --- Execute ARIMA Analysis ---\n",
    "arima_predictions, fitted_arima = run_arima_grid_search(train_data, test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "# Note: The test data for comparison must match the number of predictions.\n",
    "# ARIMA forecast length can sometimes be off by one depending on the data.\n",
    "test_close_prices = test_data['Close'].iloc[:len(arima_predictions)]\n",
    "arima_mae = mean_absolute_error(test_close_prices, arima_predictions)\n",
    "\n",
    "print(\"\\n--- ARIMA Model Evaluation ---\")\n",
    "print(f\"Test Mean Absolute Error (MAE): {arima_mae:.6f}\")\n",
    "\n",
    "# Save the fitted ARIMA model\n",
    "model_filename = os.path.join(MODEL_DIR, f\"{COMPANY}_arima_model.pkl\")\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(fitted_arima, f)\n",
    "print(f\"Model saved to: {model_filename}\")\n",
    "print(\"==============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b1dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and Descale Predictions\n",
    "def inverse_transform_predictions(scaled_predictions, column_name, scalers_dict):\n",
    "    \"\"\"Inverse transform scaled predictions back to original scale.\"\"\"\n",
    "    if column_name in scalers_dict:\n",
    "        scaler = scalers_dict[column_name]\n",
    "        \n",
    "        # Ensure input is at least 2D for the scaler\n",
    "        if scaled_predictions.ndim == 1:\n",
    "            scaled_predictions = scaled_predictions.reshape(-1, 1)\n",
    "            \n",
    "        # Descale the data\n",
    "        descaled = scaler.inverse_transform(scaled_predictions)\n",
    "        \n",
    "        # Return the data in its original shape (1D or 2D)\n",
    "        return descaled.squeeze() if descaled.shape[1] == 1 else descaled\n",
    "        \n",
    "    print(f\"Scaler for column '{column_name}' not found!\")\n",
    "    return scaled_predictions\n",
    "\n",
    "# Align Predictions for Fair Comparison\n",
    "print(\"===== Aligning Predictions for Fair Comparison =====\")\n",
    "\n",
    "# Generate and descale predictions first\n",
    "try:\n",
    "    print(\"===== Generating and Descaling Model Predictions =====\")\n",
    "    descaled_lstm_predictions = inverse_transform_predictions(lstm_model.predict(X_test, verbose=0), 'Close', scalers)\n",
    "    descaled_gru_predictions = inverse_transform_predictions(gru_model.predict(X_test, verbose=0), 'Close', scalers)\n",
    "    descaled_rnn_predictions = inverse_transform_predictions(rnn_model.predict(X_test, verbose=0), 'Close', scalers)\n",
    "    descaled_rf_predictions = inverse_transform_predictions(rf_model.predict(X_test_rf), 'Close', scalers)\n",
    "    descaled_arima_predictions = arima_predictions  \n",
    "    \n",
    "    print(\"\\nDescaled Predictions (first 10 of first day):\")\n",
    "    print(f\"LSTM: {descaled_lstm_predictions[:10, 0] if descaled_lstm_predictions.ndim > 1 else descaled_lstm_predictions[:10]}\")\n",
    "    print(f\"GRU: {descaled_gru_predictions[:10, 0] if descaled_gru_predictions.ndim > 1 else descaled_gru_predictions[:10]}\")\n",
    "    print(f\"RNN: {descaled_rnn_predictions[:10, 0] if descaled_rnn_predictions.ndim > 1 else descaled_rnn_predictions[:10]}\")\n",
    "    print(f\"Random Forest: {descaled_rf_predictions[:10, 0] if descaled_rf_predictions.ndim > 1 else descaled_rf_predictions[:10]}\")\n",
    "    print(f\"ARIMA: {descaled_arima_predictions[:10]}\")\n",
    "    print(\"‚úÖ All predictions generated successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during prediction generation: {e}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "try:\n",
    "    # First, we need to descale the ground truth (y_test) to compare with our descaled predictions\n",
    "    descaled_y_test = inverse_transform_predictions(y_test, 'Close', scalers)\n",
    "    \n",
    "    # Find the minimum length among all predictions and the ground truth.\n",
    "    # This handles any small discrepancies in length from different models (e.g., ARIMA).\n",
    "    min_len = min(\n",
    "        len(descaled_y_test),\n",
    "        len(descaled_lstm_predictions),\n",
    "        len(descaled_gru_predictions),\n",
    "        len(descaled_rnn_predictions),\n",
    "        len(descaled_rf_predictions),\n",
    "        len(descaled_arima_predictions)\n",
    "    )\n",
    "    \n",
    "    print(f\"Aligning all data to the minimum length of: {min_len}\")\n",
    "    \n",
    "    # Align all arrays by taking the last 'min_len' elements\n",
    "    aligned_y_test = descaled_y_test[-min_len:]\n",
    "    aligned_lstm_preds = descaled_lstm_predictions[-min_len:]\n",
    "    aligned_gru_preds = descaled_gru_predictions[-min_len:]\n",
    "    aligned_rnn_preds = descaled_rnn_predictions[-min_len:]\n",
    "    aligned_rf_preds = descaled_rf_predictions[-min_len:]\n",
    "    aligned_arima_preds = descaled_arima_predictions[-min_len:]\n",
    "    \n",
    "    print(\"‚úÖ All predictions and ground truth data are now aligned.\")\n",
    "    print(f\"  - Shape of aligned_y_test: {aligned_y_test.shape}\")\n",
    "    print(f\"  - Shape of aligned_lstm_preds: {aligned_lstm_preds.shape}\")\n",
    "    print(f\"  - Shape of aligned_arima_preds: {aligned_arima_preds.shape}\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"‚ùå Error: A required prediction variable is missing: {e}\")\n",
    "    print(\"   Please ensure all model training and prediction cells were run successfully.\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå An unexpected error occurred during alignment: {e}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "# Generate predictions\n",
    "try:\n",
    "    descaled_lstm_predictions = inverse_transform_predictions(lstm_model.predict(X_test, verbose=0), 'Close', scalers)\n",
    "    descaled_gru_predictions = inverse_transform_predictions(gru_model.predict(X_test, verbose=0), 'Close', scalers)\n",
    "    descaled_rnn_predictions = inverse_transform_predictions(rnn_model.predict(X_test, verbose=0), 'Close', scalers)\n",
    "    descaled_rf_predictions = inverse_transform_predictions(rf_model.predict(X_test_rf), 'Close', scalers)\n",
    "    descaled_arima_predictions = arima_predictions  \n",
    "    \n",
    "    print(\"\\nDescaled Predictions (first 10):\")\n",
    "    print(f\"LSTM: {descaled_lstm_predictions[:10]}\")\n",
    "    print(f\"GRU: {descaled_gru_predictions[:10]}\")\n",
    "    print(f\"RNN: {descaled_rnn_predictions[:10]}\")\n",
    "    print(f\"Random Forest: {descaled_rf_predictions[:10]}\")\n",
    "    print(f\"ARIMA: {descaled_arima_predictions[:10]}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during prediction: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a074bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Ensemble Based on Performance\n",
    "print(\"===== Creating Performance-Weighted Ensemble =====\")\n",
    "\n",
    "# Calculate individual model weights (inverse of MAE)\n",
    "individual_maes = {\n",
    "    'LSTM': mean_absolute_error(aligned_y_test, aligned_lstm_preds),\n",
    "    'GRU': mean_absolute_error(aligned_y_test, aligned_gru_preds), \n",
    "    'RNN': mean_absolute_error(aligned_y_test, aligned_rnn_preds),\n",
    "    'Moving Average': mean_absolute_error(aligned_y_test[:, 0], aligned_arima_preds)\n",
    "}\n",
    "\n",
    "# Calculate weights (inverse MAE, normalized)\n",
    "weights = {}\n",
    "total_inverse_mae = 0\n",
    "for model, mae in individual_maes.items():\n",
    "    inverse_mae = 1 / mae\n",
    "    weights[model] = inverse_mae\n",
    "    total_inverse_mae += inverse_mae\n",
    "\n",
    "# Normalize weights\n",
    "for model in weights:\n",
    "    weights[model] = weights[model] / total_inverse_mae\n",
    "\n",
    "print(\"Model weights:\")\n",
    "for model, weight in weights.items():\n",
    "    print(f\"{model}: {weight:.4f}\")\n",
    "\n",
    "# Tile the 1D ARIMA predictions to match the 30-day horizon of the other models,\n",
    "# filling subsequent days with NaN so they don't affect the average.\n",
    "arima_preds_30day = np.full_like(aligned_lstm_preds, np.nan)\n",
    "arima_preds_30day[:, 0] = aligned_arima_preds\n",
    "\n",
    "# Create weighted ensemble\n",
    "weighted_ensemble = (\n",
    "    weights['LSTM'] * aligned_lstm_preds +\n",
    "    weights['GRU'] * aligned_gru_preds +\n",
    "    weights['RNN'] * aligned_rnn_preds +\n",
    "    # Use np.nan_to_num to treat NaNs as zero in the sum\n",
    "    weights['Moving Average'] * np.nan_to_num(arima_preds_30day)\n",
    ")\n",
    "\n",
    "weighted_ensemble_mae = mean_absolute_error(aligned_y_test, weighted_ensemble)\n",
    "print(f\"Weighted Ensemble MAE: {weighted_ensemble_mae:.6f}\")\n",
    "\n",
    "# Compare with best individual model\n",
    "best_individual_mae = min(individual_maes.values())\n",
    "print(f\"Best Individual MAE: {best_individual_mae:.6f}\")\n",
    "print(f\"Weighted ensemble improvement: {((best_individual_mae - weighted_ensemble_mae) / best_individual_mae * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b1712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MAE for each model\n",
    "try:\n",
    "    # Load the cleaned data file\n",
    "    complete_data = pd.read_csv(cleaned_data_filename)\n",
    "    complete_data['Date'] = pd.to_datetime(complete_data['Date'])\n",
    "    print(f\"‚úÖ Loaded complete data with shape: {complete_data.shape}\")\n",
    "    print(f\"‚úÖ Date range: {complete_data['Date'].min()} to {complete_data['Date'].max()}\")\n",
    "    \n",
    "    # Display first few rows to verify\n",
    "    print(\"\\nComplete data sample:\")\n",
    "    print(complete_data.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: Could not find {cleaned_data_filename}\")\n",
    "    print(\"Please make sure the data cleaning step was completed successfully.\")\n",
    "    \n",
    "    # Alternative: Recreate from train and test data\n",
    "    print(\"Attempting to recreate complete_data from train and test data...\")\n",
    "    try:\n",
    "        complete_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "        complete_data['Date'] = pd.to_datetime(complete_data['Date'])\n",
    "        print(f\"‚úÖ Recreated complete data with shape: {complete_data.shape}\")\n",
    "    except:\n",
    "        print(\"‚ùå Could not recreate complete_data. Please run the data loading steps.\")\n",
    "        raise\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading complete data: {e}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "# Let's analyze your model performance more clearly\n",
    "print(\"=== MODEL PERFORMANCE ANALYSIS ===\")\n",
    "\n",
    "# Calculate percentage errors for better understanding\n",
    "current_price = complete_data['Close'].iloc[-1]\n",
    "print(f\"Current stock price: ${current_price:.2f}\")\n",
    "\n",
    "# Calculate relative MAE (as percentage of current price)\n",
    "individual_maes = {\n",
    "    'LSTM': mean_absolute_error(aligned_y_test, aligned_lstm_preds),\n",
    "    'GRU': mean_absolute_error(aligned_y_test, aligned_gru_preds), \n",
    "    'RNN': mean_absolute_error(aligned_y_test, aligned_rnn_preds),\n",
    "    'Random Forest': mean_absolute_error(aligned_y_test, aligned_rf_preds),\n",
    "    'ARIMA (Day 1)': mean_absolute_error(aligned_y_test[:, 0], aligned_arima_preds)\n",
    "}\n",
    "\n",
    "print(\"\\n--- Individual Model Performance ---\")\n",
    "for model, mae in individual_maes.items():\n",
    "    mae_percentage = (mae / current_price) * 100\n",
    "    performance = \"Good\" if mae_percentage < 3 else \"Poor\" if mae_percentage > 7 else \"Average\"\n",
    "    print(f\"{model}: MAE=${mae:.4f} ({mae_percentage:.2f}%) - {performance}\")\n",
    "\n",
    "print(\"\\n--- Ensemble Performance ---\")\n",
    "# --- FIX: Create the simple average ensemble predictions before evaluating them ---\n",
    "# These ensembles average the multi-step (30-day) forecasts from the NN and RF models.\n",
    "ensemble_lstm_gru = (aligned_lstm_preds + aligned_gru_preds) / 2.0\n",
    "ensemble_lstm_gru_rf = (aligned_lstm_preds + aligned_gru_preds + aligned_rf_preds) / 3.0\n",
    "ensemble_all_nn_rf = (aligned_lstm_preds + aligned_gru_preds + aligned_rnn_preds + aligned_rf_preds) / 4.0\n",
    "# A simple average of all models including ARIMA is more complex due to shape differences.\n",
    "# It is handled separately in the 'Weighted Ensemble' and 'Stacked Ensemble' sections.\n",
    "# We define a simple version for a single-day MAE calculation.\n",
    "ensemble_mae_all = mean_absolute_error(aligned_y_test, ensemble_all_nn_rf)\n",
    "\n",
    "\n",
    "# FIX: The ensemble MAEs also need to be calculated correctly.\n",
    "# We will compare multi-step ensembles against the full 30-day horizon,\n",
    "# and ensembles including ARIMA against only the first day.\n",
    "ensemble_maes = {\n",
    "    'Ensemble LSTM+GRU': mean_absolute_error(aligned_y_test, ensemble_lstm_gru),\n",
    "    'Ensemble LSTM+GRU+RF': mean_absolute_error(aligned_y_test, ensemble_lstm_gru_rf),\n",
    "    'Ensemble All NN/RF': mean_absolute_error(aligned_y_test, ensemble_all_nn_rf),\n",
    "    # Note: The simple average ensemble with ARIMA is not straightforward to evaluate\n",
    "    # across the full 30 days, so we omit it here for clarity.\n",
    "    # The 'Weighted Ensemble' from the previous cell is a better approach.\n",
    "}\n",
    "\n",
    "for ensemble, mae in ensemble_maes.items():\n",
    "    mae_percentage = (mae / current_price) * 100\n",
    "    performance = \"Good\" if mae_percentage < 3 else \"Poor\" if mae_percentage > 7 else \"Average\"\n",
    "    print(f\"{ensemble}: MAE=${mae:.4f} ({mae_percentage:.2f}%) - {performance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ed547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Stacked Ensemble Modeling\n",
    "# Model Evaluation and Visualization\n",
    "# Interactive Candlestick Visualization\n",
    "# Boxplot Analysis\n",
    "# Multistep Prediction Functions\n",
    "# Advanced Future Predictions\n",
    "# Advanced Interactive Visualization\n",
    "# Export Results and Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Stacked Ensemble Modeling\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def create_stacked_ensemble(models_dict, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Create a stacked ensemble with meta-learner\"\"\"\n",
    "    # Generate predictions from base models\n",
    "    train_predictions = []\n",
    "    test_predictions = []\n",
    "    \n",
    "    print(\"Generating base model predictions for stacking...\")\n",
    "    for name, model in models_dict.items():\n",
    "        if hasattr(model, 'predict'):\n",
    "            if name == 'rf':\n",
    "                # For Random Forest, create the specific features it was trained on\n",
    "                X_train_rf_stack, _ = create_rf_features(X_train, y_train)\n",
    "                X_test_rf_stack, _ = create_rf_features(X_test, y_test)\n",
    "                train_pred = model.predict(X_train_rf_stack) # Shape: (samples, 30)\n",
    "                test_pred = model.predict(X_test_rf_stack)   # Shape: (samples, 30)\n",
    "            else:  # Neural networks\n",
    "                # Predict to get the 30-day forecast for each sample\n",
    "                train_pred = model.predict(X_train, verbose=0) # Shape: (samples, 30)\n",
    "                test_pred = model.predict(X_test, verbose=0)   # Shape: (samples, 30)\n",
    "            \n",
    "            # All predictions should now have shape (samples, 30)\n",
    "            train_predictions.append(train_pred)\n",
    "            test_predictions.append(test_pred)\n",
    "            print(f\"  - Generated predictions for {name.upper()}. Shape: {train_pred.shape}\")\n",
    "    # Stack predictions for the meta-learner. This creates the new feature set.\n",
    "    # Each model's 30-day forecast becomes 30 features.\n",
    "    X_train_stack = np.hstack(train_predictions) # Shape: (samples, num_models * 30)\n",
    "    X_test_stack = np.hstack(test_predictions)   # Shape: (samples, num_models * 30)\n",
    "    print(f\"Stacked training features shape: {X_train_stack.shape}\")\n",
    "    \n",
    "    # Train the meta-learner\n",
    "    print(\"Training meta-learner...\")\n",
    "    meta_learner = LinearRegression()\n",
    "    # FIX: Train the meta-learner on the base models' predictions on the TRAINING set.\n",
    "    # This prevents data leakage.\n",
    "    meta_learner.fit(X_train_stack, y_train)\n",
    "    \n",
    "    # Make final predictions\n",
    "    print(\"Making final stacked predictions...\")\n",
    "    final_predictions = meta_learner.predict(X_test_stack)\n",
    "    \n",
    "    return final_predictions, meta_learner\n",
    "\n",
    "# Apply stacked ensemble\n",
    "print(\"===== Creating Stacked Ensemble =====\")\n",
    "try:\n",
    "    # Prepare models dictionary for stacking\n",
    "    models_for_stacking = {\n",
    "        'lstm': lstm_model,\n",
    "        'gru': gru_model,\n",
    "        'rnn': rnn_model,\n",
    "        'rf': rf_model\n",
    "    }\n",
    "    \n",
    "    # Create the stacked ensemble model\n",
    "    stacked_predictions, meta_learner = create_stacked_ensemble(\n",
    "        models_for_stacking, X_train, y_train, X_test, y_test\n",
    "    )\n",
    "    \n",
    "    # Descale the stacked predictions to the original price scale\n",
    "    descaled_stacked_predictions = inverse_transform_predictions(stacked_predictions, 'Close', scalers)\n",
    "    \n",
    "    # Align predictions for fair comparison\n",
    "    # FIX: Define min_len based on the new descaled_stacked_predictions\n",
    "    min_len = min(len(descaled_stacked_predictions), len(aligned_y_test))\n",
    "    aligned_stacked_preds = descaled_stacked_predictions[-min_len:]\n",
    "    aligned_y_test_stacked = aligned_y_test[-min_len:]\n",
    "    \n",
    "    # Evaluate the stacked ensemble's performance\n",
    "    stacked_mae = mean_absolute_error(aligned_y_test_stacked, aligned_stacked_preds)\n",
    "    stacked_mse = mean_squared_error(aligned_y_test_stacked, aligned_stacked_preds)\n",
    "    stacked_rmse = np.sqrt(stacked_mse)\n",
    "    \n",
    "    print(\"\\n--- Stacked Ensemble Performance ---\")\n",
    "    print(f\"Stacked Ensemble MAE: {stacked_mae:.6f}\")\n",
    "    print(f\"Stacked Ensemble MSE: {stacked_mse:.6f}\")\n",
    "    print(f\"Stacked Ensemble RMSE: {stacked_rmse:.6f}\")\n",
    "    \n",
    "    # Compare with the simple average ensemble\n",
    "    print(\"\\n--- Ensemble Comparison ---\")\n",
    "    print(f\"Simple Average All Models MAE: {ensemble_mae_all:.6f}\")\n",
    "    print(f\"Stacked Ensemble MAE: {stacked_mae:.6f}\")\n",
    "    \n",
    "    if stacked_mae < ensemble_mae_all:\n",
    "        improvement = ((ensemble_mae_all - stacked_mae) / ensemble_mae_all) * 100\n",
    "        print(f\"üéâ Stacked ensemble is better by {improvement:.2f}%\")\n",
    "        # Update the 'best_ensemble' variables for subsequent cells\n",
    "        best_ensemble = 'Stacked_Ensemble'\n",
    "        best_mae = stacked_mae\n",
    "        ensemble_all = aligned_stacked_preds # Used in visualization\n",
    "    else:\n",
    "        improvement = ((stacked_mae - ensemble_mae_all) / ensemble_mae_all) * 100\n",
    "        print(f\"Simple average ensemble is better by {improvement:.2f}%\")\n",
    "\n",
    "    print(\"======================================\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in stacked ensemble: {e}\")\n",
    "    \n",
    "# Initialize dictionaries and dataframes for subsequent analysis cells\n",
    "# This ensures they exist before the stacked ensemble integration cell is run.\n",
    "print(\"\\nInitializing data structures for further analysis...\")\n",
    "aligned_y_test_for_arima = aligned_y_test[:, 0]\n",
    "ensemble_mae_arima_lstm_gru_rf = mean_absolute_error(aligned_y_test_for_arima, (aligned_arima_preds + aligned_lstm_preds[:, 0] + aligned_gru_preds[:, 0] + aligned_rf_preds[:, 0]) / 4.0)\n",
    "ensemble_mae_arima_lstm = mean_absolute_error(aligned_y_test_for_arima, (aligned_arima_preds + aligned_lstm_preds[:, 0]) / 2.0)\n",
    "ensemble_mae_arima_lstm_gru = mean_absolute_error(aligned_y_test_for_arima, (aligned_arima_preds + aligned_lstm_preds[:, 0] + aligned_gru_preds[:, 0]) / 3.0)\n",
    "ensemble_mae_arima_lstm_gru_rf = mean_absolute_error(aligned_y_test_for_arima, (aligned_arima_preds + aligned_lstm_preds[:, 0] + aligned_gru_preds[:, 0] + aligned_rf_preds[:, 0]) / 4.0)\n",
    "# FIX: Calculate the actual ensemble predictions for visualization.\n",
    "# These are the single-day forecasts that combine ARIMA with other models.\n",
    "ensemble_preds_arima_lstm = (aligned_arima_preds + aligned_lstm_preds[:, 0]) / 2.0\n",
    "ensemble_preds_arima_lstm_gru = (aligned_arima_preds + aligned_lstm_preds[:, 0] + aligned_gru_preds[:, 0]) / 3.0\n",
    "ensemble_preds_arima_lstm_gru_rf = (aligned_arima_preds + aligned_lstm_preds[:, 0] + aligned_gru_preds[:, 0] + aligned_rf_preds[:, 0]) / 4.0\n",
    "\n",
    "\n",
    "# Dictionary to hold ensemble model names and their MAE scores\n",
    "ensemble_models = {\n",
    "    'Ensemble_MA_LSTM': ensemble_mae_arima_lstm,\n",
    "    'Ensemble_MA_LSTM_GRU': ensemble_mae_arima_lstm_gru,\n",
    "    'Ensemble_MA_LSTM_GRU_RF': ensemble_mae_arima_lstm_gru_rf,\n",
    "    'Ensemble_All': ensemble_mae_all\n",
    "}\n",
    "\n",
    "# DataFrame to hold all predictions for visualization\n",
    "# Get the correct dates for the test predictions\n",
    "prediction_dates = test_data['Date'].iloc[PREDICTION_DAYS:PREDICTION_DAYS + len(aligned_y_test)].values\n",
    "\n",
    "predictions_viz_data = pd.DataFrame({\n",
    "    'Date': prediction_dates,\n",
    "    'Actual': aligned_y_test[:, 0],\n",
    "    'LSTM': aligned_lstm_preds[:, 0],\n",
    "    'GRU': aligned_gru_preds[:, 0],\n",
    "    'RNN': aligned_rnn_preds[:, 0],\n",
    "    'Random_Forest': aligned_rf_preds[:, 0],\n",
    "    'ARIMA': aligned_arima_preds,\n",
    "    'Ensemble_MA_LSTM': ensemble_preds_arima_lstm,\n",
    "    'Ensemble_MA_LSTM_GRU': ensemble_preds_arima_lstm_gru,\n",
    "    'Ensemble_MA_LSTM_GRU_RF': ensemble_preds_arima_lstm_gru_rf,\n",
    "    'Ensemble_All': ensemble_all_nn_rf[:, 0]\n",
    "})\n",
    "\n",
    "print(\"‚úÖ Initialized 'ensemble_models' and 'predictions_viz_data'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f7fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate Stacked Model into Final Analysis\n",
    "print(\"===== Integrating Stacked Ensemble into Final Analysis =====\")\n",
    "\n",
    "try:\n",
    "    # Add the stacked model's performance to the ensemble metrics dictionary\n",
    "    # This dictionary is used later for finding the best model\n",
    "    ensemble_models['Stacked_Ensemble'] = stacked_mae\n",
    "    \n",
    "    # Add the stacked model's predictions to the visualization dataframe\n",
    "    # This dataframe is used by the advanced interactive plot\n",
    "    # We take only the first day of the prediction for single-day comparison plots\n",
    "    predictions_viz_data['Stacked_Ensemble'] = aligned_stacked_preds[:, 0]\n",
    "    \n",
    "    # Re-determine the best overall model now that the stacked model is included\n",
    "    best_ensemble = min(ensemble_models, key=lambda k: ensemble_models[k])\n",
    "    best_mae = ensemble_models[best_ensemble]\n",
    "    \n",
    "    print(f\"\\n‚úÖ Stacked model integrated. The new best performing model is: '{best_ensemble}' with MAE: {best_mae:.6f}\")\n",
    "    \n",
    "    # Display the final, updated model ranking\n",
    "    print(\"\\n--- Final Model Performance Ranking ---\")\n",
    "    \n",
    "    # Combine individual and ensemble model performances for a complete ranking\n",
    "    all_models_performance = {\n",
    "        'LSTM': mean_absolute_error(aligned_y_test, aligned_lstm_preds),\n",
    "        'GRU': mean_absolute_error(aligned_y_test, aligned_gru_preds),\n",
    "        'RNN': mean_absolute_error(aligned_y_test, aligned_rnn_preds),\n",
    "        'Random Forest': mean_absolute_error(aligned_y_test, aligned_rf_preds),\n",
    "        # FIX: Compare ARIMA (1D) against the first day of the y_test target (1D)\n",
    "        'ARIMA': mean_absolute_error(aligned_y_test[:, 0], aligned_arima_preds),\n",
    "        'Ensemble_MA_LSTM': ensemble_mae_arima_lstm,\n",
    "        'Ensemble_MA_LSTM_GRU': ensemble_mae_arima_lstm_gru,\n",
    "        'Ensemble_MA_LSTM_GRU_RF': ensemble_mae_arima_lstm_gru_rf,\n",
    "        'Ensemble_All': ensemble_mae_all,\n",
    "        **ensemble_models\n",
    "    }\n",
    "    \n",
    "    # Sort and print the ranked models by MAE\n",
    "    sorted_models = sorted(all_models_performance.items(), key=lambda item: item[1])\n",
    "    for i, (model, mae) in enumerate(sorted_models, 1):\n",
    "        print(f\"{i}. {model}: MAE = {mae:.6f}\")\n",
    "        \n",
    "    print(\"\\n=======================================================\")\n",
    "    print(\"You can now proceed to the 'Advanced Future Predictions' and 'Advanced Interactive Visualization' cells.\")\n",
    "    print(\"They will automatically use the best model, which may now be the Stacked Ensemble.\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"‚ùå Error: Could not integrate the stacked model. Please ensure the stacked ensemble cell was run successfully.\")\n",
    "    print(f\"Details: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå An unexpected error occurred during integration: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c9f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation and Visualization\n",
    "# --- Prepare Data for Evaluation ---\n",
    "# Extract the actual prices and dates from the dataframe\n",
    "actual_prices = predictions_viz_data['Actual']\n",
    "prediction_dates = predictions_viz_data['Date']\n",
    "\n",
    "# Get a list of all model prediction columns to iterate over\n",
    "model_columns = [col for col in predictions_viz_data.columns if col not in ['Date', 'Actual']]\n",
    "\n",
    "# --- Calculate and Display Overall Metrics ---\n",
    "metrics = []\n",
    "for model_name in model_columns:\n",
    "    pred_prices = predictions_viz_data[model_name]\n",
    "    mae = mean_absolute_error(actual_prices, pred_prices)\n",
    "    mse = mean_squared_error(actual_prices, pred_prices)\n",
    "    rmse = np.sqrt(mse)\n",
    "    metrics.append({'Model': model_name, 'MAE ($)': mae, 'MSE': mse, 'RMSE ($)': rmse})\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics).set_index('Model')\n",
    "print(\"\\n--- Overall Prediction Performance Metrics (Sorted by MAE) ---\")\n",
    "print(metrics_df.sort_values('MAE ($)').round(4))\n",
    "print(\"==============================================================\")\n",
    "\n",
    "\n",
    "# --- Detailed Analysis and Visualization for Each Model ---\n",
    "for model_name in model_columns:\n",
    "    print(f\"\\n--- Detailed Analysis for {model_name} Model ---\")\n",
    "    \n",
    "    # Create a results DataFrame for the current model\n",
    "    results_df = pd.DataFrame({\n",
    "        'Date': prediction_dates,\n",
    "        'Actual_Price': actual_prices.values,\n",
    "        'Predicted_Price': predictions_viz_data[model_name].values\n",
    "    })\n",
    "    results_df['Error'] = results_df['Actual_Price'] - results_df['Predicted_Price']\n",
    "    results_df['Absolute_Error'] = np.abs(results_df['Error'])\n",
    "    \n",
    "    # Save this model's predictions to a CSV file\n",
    "    predictions_filename = os.path.join(DATA_DIR, f\"{COMPANY}_predictions_{model_name}.csv\")\n",
    "    results_df.to_csv(predictions_filename, index=False)\n",
    "    print(f\"‚úÖ Predictions for {model_name} saved to: {predictions_filename}\")\n",
    "    \n",
    "    # Plot predictions vs. actuals and the prediction errors\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10), sharex=True)\n",
    "    fig.suptitle(f'{model_name} Model: Prediction Analysis', fontsize=16)\n",
    "    \n",
    "    ax1.plot(results_df['Date'], results_df['Actual_Price'], label='Actual Prices', color='blue', linestyle='-', marker='.', alpha=0.7)\n",
    "    ax1.plot(results_df['Date'], results_df['Predicted_Price'], label='Predicted Prices', color='red', linestyle='-', alpha=0.8)\n",
    "    ax1.set_ylabel('Stock Price ($)')\n",
    "    ax1.set_title('Actual vs. Predicted Prices')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    ax2.plot(results_df['Date'], results_df['Error'], label='Prediction Error', color='green', linestyle='-')\n",
    "    ax2.axhline(y=0, color='black', linestyle='--', linewidth=0.8)\n",
    "    ax2.set_xlabel('Date')\n",
    "    ax2.set_ylabel('Prediction Error ($)')\n",
    "    ax2.set_title('Prediction Errors')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    # Improve date formatting on the x-axis\n",
    "    fig.autofmt_xdate()\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "    \n",
    "    # Show the best and worst predictions for this model\n",
    "    print(\"\\n--- Prediction Highlights & Lowlights ---\")\n",
    "    print(\"\\n‚úÖ 5 Best Predictions (Lowest Absolute Error):\")\n",
    "    print(results_df.sort_values('Absolute_Error').head(5).round(2))\n",
    "    print(\"\\n‚ùå 5 Worst Predictions (Highest Absolute Error):\")\n",
    "    print(results_df.sort_values('Absolute_Error', ascending=False).head(5).round(2))\n",
    "    \n",
    "    print(\"\\n--- Statistical Summary of Errors ---\")\n",
    "    print(results_df['Error'].describe().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cde7ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Candlestick Visualization\n",
    "\n",
    "# --- Prerequisite Check ---\n",
    "try:\n",
    "    predictions_viz_data\n",
    "    print(\"‚úÖ Found 'predictions_viz_data' DataFrame. Ready for visualization.\")\n",
    "except NameError:\n",
    "    print(\"‚ùå CRITICAL ERROR: 'predictions_viz_data' DataFrame not found.\")\n",
    "    print(\"   Please ensure the 'Ensemble Modeling' and 'Improved Stacked Ensemble Modeling' cells have been run successfully.\")\n",
    "    raise\n",
    "\n",
    "# --- Visualization Functions (no changes needed) ---\n",
    "def create_candlestick_data(df, n_days=1):\n",
    "    \"\"\"Aggregate daily data into N-day candlesticks.\"\"\"\n",
    "    df = df.copy()\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    if n_days == 1:\n",
    "        return df\n",
    "    grouped = df.groupby(np.arange(len(df)) // n_days).agg(\n",
    "        Date=('Date', 'first'),\n",
    "        Open=('Open', 'first'),\n",
    "        High=('High', 'max'),\n",
    "        Low=('Low', 'min'),\n",
    "        Close=('Close', 'last'),\n",
    "        Volume=('Volume', 'sum'),\n",
    "        Actual_Price=('Actual_Price', 'last'),\n",
    "        Predicted_Price=('Predicted_Price', 'last'),\n",
    "    )\n",
    "    return grouped\n",
    "\n",
    "def plot_prediction_candlesticks(df, title, n_days, limit_days):\n",
    "    \"\"\"Create a candlestick chart with predictions overlay.\"\"\"\n",
    "    plot_data = df.copy()\n",
    "    if limit_days:\n",
    "        plot_data = plot_data.tail(limit_days)\n",
    "    plot_data = create_candlestick_data(plot_data, n_days=n_days)\n",
    "    \n",
    "    if plot_data.empty:\n",
    "        print(\"No data available to plot.\")\n",
    "        return\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10), sharex=True)\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    plot_data['Date_Num'] = mdates.date2num(pd.to_datetime(plot_data['Date']))\n",
    "    width = 0.8 * n_days\n",
    "    \n",
    "    for index, row in plot_data.iterrows():\n",
    "        color = 'green' if row['Close'] >= row['Open'] else 'red'\n",
    "        ax1.plot([row['Date_Num'], row['Date_Num']], [row['Low'], row['High']], color='black', linewidth=1)\n",
    "        body = Rectangle((row['Date_Num'] - width/2, min(row['Open'], row['Close'])), width, abs(row['Close'] - row['Open']), facecolor=color, edgecolor='black')\n",
    "        ax1.add_patch(body)\n",
    "    \n",
    "    ax1.plot(plot_data['Date_Num'], plot_data['Actual_Price'], label='Actual Price', color='blue', linestyle='--', alpha=0.9, linewidth=2)\n",
    "    ax1.plot(plot_data['Date_Num'], plot_data['Predicted_Price'], label='Predicted Price', color='orange', linestyle='-', alpha=0.9, linewidth=2)\n",
    "    ax1.set_ylabel('Price ($)')\n",
    "    ax1.set_title('Actual vs. Predicted Prices')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    volume_colors = ['green' if row['Close'] >= row['Open'] else 'red' for _, row in plot_data.iterrows()]\n",
    "    ax2.bar(plot_data['Date_Num'], plot_data['Volume'], width=width, color=volume_colors, alpha=0.6)\n",
    "    ax2.set_ylabel('Volume')\n",
    "    ax2.set_title('Volume')\n",
    "    ax2.grid(True, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    fig.autofmt_xdate()\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "# --- Interactive Loop ---\n",
    "# Get the list of all available models for visualization\n",
    "available_models = [col for col in predictions_viz_data.columns if col not in ['Date', 'Actual']]\n",
    "model_map = {str(i + 1): model for i, model in enumerate(available_models)}\n",
    "\n",
    "while True:\n",
    "    print(\"\\n--- Interactive Candlestick Visualization ---\")\n",
    "    # Dynamically create the menu of all available models\n",
    "    for key, model_name in model_map.items():\n",
    "        print(f\"{key}: {model_name}\")\n",
    "    print(\"q: Quit\")\n",
    "    \n",
    "    choice = input(f\"Enter your choice (1-{len(model_map)}/q): \").strip().lower()\n",
    "    \n",
    "    if choice == 'q':\n",
    "        print(\"Exiting visualization.\")\n",
    "        break\n",
    "    \n",
    "    if choice not in model_map:\n",
    "        print(\"‚ùå Invalid choice. Please select a number from the list.\")\n",
    "        continue\n",
    "    \n",
    "    model_name = model_map[choice]\n",
    "    \n",
    "    try:\n",
    "        n_days_input = input(\"Enter number of days per candlestick (default: 1): \").strip()\n",
    "        n_days = int(n_days_input) if n_days_input else 1\n",
    "        \n",
    "        limit_days_input = input(\"Enter number of recent days to display (default: 90): \").strip()\n",
    "        limit_days = int(limit_days_input) if limit_days_input else 90\n",
    "    except ValueError:\n",
    "        print(\"‚ùå Invalid number. Using defaults.\")\n",
    "        n_days, limit_days = 1, 90\n",
    "    \n",
    "    try:\n",
    "        # --- Prepare DataFrame for Plotting ---\n",
    "        # Merge OHLCV data from `test_data` with predictions from `predictions_viz_data`.\n",
    "        \n",
    "        pred_subset = predictions_viz_data[['Date', 'Actual', model_name]].copy()\n",
    "        \n",
    "        # The original data uses 'Price' for the open price. Rename it to 'Open' for the plot.\n",
    "        if 'Open' not in test_data.columns and 'Price' in test_data.columns:\n",
    "             test_data_plot = test_data.rename(columns={'Price': 'Open'})\n",
    "        else:\n",
    "             test_data_plot = test_data.copy()\n",
    "\n",
    "        # Merge on 'Date' to ensure data is perfectly aligned\n",
    "        plot_df = pd.merge(test_data_plot, pred_subset, on='Date', how='inner')\n",
    "        \n",
    "        # Rename columns to what the plotting function expects\n",
    "        plot_df = plot_df.rename(columns={'Actual': 'Actual_Price', model_name: 'Predicted_Price'})\n",
    "        \n",
    "        # Call the plotting function\n",
    "        plot_prediction_candlesticks(\n",
    "            plot_df, \n",
    "            f\"{COMPANY} - {model_name} Model Predictions\", \n",
    "            n_days, \n",
    "            limit_days\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An unexpected error occurred while preparing the plot:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c41186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot Analysis\n",
    "# --- Visualization Functions (no changes needed) ---\n",
    "def create_boxplot_data(df, period='monthly'):\n",
    "    \"\"\"Prepare data for boxplot visualization.\"\"\"\n",
    "    df_copy = df.copy()\n",
    "    df_copy['Date'] = pd.to_datetime(df_copy['Date'])\n",
    "    \n",
    "    if period == 'monthly':\n",
    "        df_copy['Period'] = df_copy['Date'].dt.strftime('%Y-%m')\n",
    "    elif period == 'quarterly':\n",
    "        df_copy['Period'] = df_copy['Date'].dt.to_period('Q').astype(str)\n",
    "    elif period == 'yearly':\n",
    "        df_copy['Period'] = df_copy['Date'].dt.year.astype(str)\n",
    "    elif period == 'weekly':\n",
    "        df_copy['Period'] = df_copy['Date'].dt.strftime('%Y-W%U')\n",
    "    else:\n",
    "        raise ValueError(\"Period must be one of 'monthly', 'quarterly', 'yearly', or 'weekly'\")\n",
    "    \n",
    "    df_copy['Price_Range'] = df_copy['High'] - df_copy['Low']\n",
    "    df_copy['Daily_Return'] = df_copy['Close'].pct_change() * 100\n",
    "    return df_copy\n",
    "\n",
    "def plot_price_boxplots(df, period='monthly'):\n",
    "    \"\"\"Create boxplots for historical stock data.\"\"\"\n",
    "    boxplot_data = create_boxplot_data(df, period)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "    fig.suptitle(f'Historical Stock Analysis by {period.title()}', fontsize=16)\n",
    "    \n",
    "    sns.boxplot(ax=axes[0, 0], data=boxplot_data, x='Period', y='Close', palette='viridis')\n",
    "    axes[0, 0].set_title('Close Price Distribution')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    sns.boxplot(ax=axes[0, 1], data=boxplot_data, x='Period', y='Price_Range', palette='plasma')\n",
    "    axes[0, 1].set_title('Daily Price Range (Volatility)')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    sns.boxplot(ax=axes[1, 0], data=boxplot_data, x='Period', y='Volume', palette='magma')\n",
    "    axes[1, 0].set_title('Trading Volume Distribution')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    sns.boxplot(ax=axes[1, 1], data=boxplot_data, x='Period', y='Daily_Return', palette='cividis')\n",
    "    axes[1, 1].set_title('Daily Returns Distribution (%)')\n",
    "    axes[1, 1].axhline(0, color='black', linestyle='--')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "def plot_prediction_error_boxplots(results_df, model_name):\n",
    "    \"\"\"Create boxplots for prediction errors.\"\"\"\n",
    "    results_df['Error'] = results_df['Actual_Price'] - results_df['Predicted_Price']\n",
    "    results_df['Absolute_Error'] = np.abs(results_df['Error'])\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    fig.suptitle(f'{model_name} Model: Prediction Error Analysis', fontsize=16)\n",
    "    \n",
    "    sns.boxplot(ax=ax1, y=results_df['Error'], palette='coolwarm')\n",
    "    ax1.axhline(0, color='black', linestyle='--')\n",
    "    ax1.set_title('Prediction Error')\n",
    "    ax1.set_ylabel('Error ($)')\n",
    "    \n",
    "    sns.boxplot(ax=ax2, y=results_df['Absolute_Error'], palette='spring')\n",
    "    ax2.set_title('Absolute Prediction Error')\n",
    "    ax2.set_ylabel('Absolute Error ($)')\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# --- Interactive Loop ---\n",
    "while True:\n",
    "    print(\"\\n--- Boxplot Analysis Menu ---\")\n",
    "    print(\"1: Historical Data Analysis\")\n",
    "    print(\"2: Prediction Error Analysis\")\n",
    "    print(\"q: Quit\")\n",
    "    choice = input(\"Enter your choice (1/2/q): \").strip().lower()\n",
    "    \n",
    "    if choice == 'q':\n",
    "        print(\"Exiting boxplot analysis.\")\n",
    "        break\n",
    "    \n",
    "    try:\n",
    "        if choice == '1':\n",
    "            print(\"\\nSelect period for historical analysis:\")\n",
    "            print(\"1: Monthly\\n2: Quarterly\\n3: Yearly\\n4: Weekly\")\n",
    "            period_choice = input(\"Enter choice [default: 1]: \").strip()\n",
    "            period_map = {'1': 'monthly', '2': 'quarterly', '3': 'yearly', '4': 'weekly'}\n",
    "            period = period_map.get(period_choice, 'monthly')\n",
    "            \n",
    "            # Concatenate train and test data to get the full historical range\n",
    "            full_historical_df = pd.concat([train_data, test_data], ignore_index=True)\n",
    "            plot_price_boxplots(full_historical_df, period=period)\n",
    "        \n",
    "        elif choice == '2':\n",
    "            # Dynamically get all available models for error analysis\n",
    "            available_models = [col for col in predictions_viz_data.columns if col not in ['Date', 'Actual']]\n",
    "            model_map = {str(i + 1): model for i, model in enumerate(available_models)}\n",
    "            \n",
    "            print(\"\\nSelect a model for prediction error analysis:\")\n",
    "            for key, model_name in model_map.items():\n",
    "                print(f\"{key}: {model_name}\")\n",
    "            \n",
    "            model_choice = input(f\"Enter choice (1-{len(model_map)}): \").strip()\n",
    "            \n",
    "            if model_choice not in model_map:\n",
    "                print(\"‚ùå Invalid model choice.\")\n",
    "                continue\n",
    "                \n",
    "            model_name = model_map[model_choice]\n",
    "            \n",
    "            # Create the dataframe for the selected model from the master visualization data\n",
    "            prediction_df = predictions_viz_data[['Actual', model_name]].copy()\n",
    "            prediction_df.rename(columns={'Actual': 'Actual_Price', model_name: 'Predicted_Price'}, inplace=True)\n",
    "            \n",
    "            plot_prediction_error_boxplots(prediction_df, model_name)\n",
    "        \n",
    "        else:\n",
    "            print(\"‚ùå Invalid choice. Please enter 1, 2, or q.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a1090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multistep Prediction Functions\n",
    "def solve_multivariate_multistep_prediction(model, last_sequence, k, scalers, feature_order):\n",
    "    \"\"\"Predict k days into the future using multivariate input.\"\"\"\n",
    "    predictions = []\n",
    "    current_sequence = last_sequence.copy()\n",
    "    \n",
    "    for _ in range(k):\n",
    "        next_close_scaled = model.predict(current_sequence.reshape(1, PREDICTION_DAYS, -1), verbose=0)[0, 0]\n",
    "        predictions.append(scalers['Close'].inverse_transform([[next_close_scaled]])[0, 0])\n",
    "        \n",
    "        new_step = current_sequence[0, -1, :].copy()\n",
    "        close_feature_index = feature_order.index('Close')\n",
    "        new_step[close_feature_index] = next_close_scaled\n",
    "        new_step = new_step.reshape(1, 1, current_sequence.shape[2])\n",
    "        current_sequence = np.append(current_sequence[:, 1:, :], new_step, axis=1)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea083b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Future Predictions\n",
    "# --- Prerequisite Checks ---\n",
    "try:\n",
    "    # Check for all necessary models and variables\n",
    "    all_models_performance\n",
    "    lstm_model\n",
    "    gru_model\n",
    "    rnn_model\n",
    "    rf_model\n",
    "    fitted_arima\n",
    "    meta_learner\n",
    "    weights\n",
    "    scalers\n",
    "    test_values\n",
    "    feature_columns\n",
    "    PREDICTION_DAYS\n",
    "    create_rf_features\n",
    "    print(\"‚úÖ All prerequisite models and variables found. Ready for future prediction.\")\n",
    "except NameError as e:\n",
    "    print(f\"‚ùå CRITICAL ERROR: A required variable or model is missing: {e}\")\n",
    "    print(\"   Please ensure all preceding cells, especially model training and ensemble creation, have been run successfully.\")\n",
    "    raise\n",
    "\n",
    "def generate_future_predictions(model_name, future_days, last_sequence, all_models, scalers, feature_columns):\n",
    "    \"\"\"\n",
    "    Generates future predictions using a direct forecasting strategy.\n",
    "    This is much simpler as it does not require a recursive loop.\n",
    "    \"\"\"\n",
    "    # Unpack all models from the dictionary\n",
    "    lstm_m = all_models.get('LSTM')\n",
    "    gru_m = all_models.get('GRU')\n",
    "    rnn_m = all_models.get('RNN')\n",
    "    rf_m = all_models.get('Random_Forest')\n",
    "    arima_m = all_models.get('ARIMA')\n",
    "    meta_learner_m = all_models.get('Stacked_Ensemble_Meta')\n",
    "    weights_m = all_models.get('Weighted_Ensemble_Weights')\n",
    "\n",
    "    print(f\"Generating a direct {future_days}-day forecast for '{model_name}'...\")\n",
    "\n",
    "    # --- Step 1: Get the full forecast from the required base models ---\n",
    "    # The input sequence is the same for all NN and RF models\n",
    "    nn_input_seq = last_sequence.reshape(1, PREDICTION_DAYS, len(feature_columns))\n",
    "\n",
    "    # Predict ONCE to get all future days for each model.\n",
    "    # The NN/RF models will predict 30 days, so we slice the result.\n",
    "    base_preds_scaled = {\n",
    "        'LSTM': lstm_m.predict(nn_input_seq, verbose=0)[0][:future_days],\n",
    "        'GRU': gru_m.predict(nn_input_seq, verbose=0)[0][:future_days],\n",
    "        'RNN': rnn_m.predict(nn_input_seq, verbose=0)[0][:future_days]\n",
    "    }\n",
    "    \n",
    "    # For RF, we must re-create the features from the sequence\n",
    "    rf_features, _ = create_rf_features(nn_input_seq, np.zeros(nn_input_seq.shape[0]))\n",
    "    base_preds_scaled['Random_Forest'] = rf_m.predict(rf_features).flatten()[:future_days]\n",
    "    \n",
    "    # ARIMA forecasts the correct number of steps natively\n",
    "    arima_preds_unscaled = arima_m.forecast(steps=future_days)\n",
    "    base_preds_scaled['ARIMA'] = scalers['Close'].transform(arima_preds_unscaled.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # --- Step 2: Select or Ensemble the forecasts ---\n",
    "    final_pred_scaled = None\n",
    "    if model_name in base_preds_scaled:\n",
    "        final_pred_scaled = base_preds_scaled[model_name]\n",
    "    \n",
    "    elif model_name == 'Ensemble_All':\n",
    "        # Average the predictions from all base models\n",
    "        final_pred_scaled = np.mean([preds for preds in base_preds_scaled.values()], axis=0)\n",
    "        \n",
    "    elif model_name == 'Stacked_Ensemble':\n",
    "        print(\"  - Using Stacked Ensemble...\")\n",
    "        # FIX: Use only the models the meta-learner was trained on (LSTM, GRU, RNN, RF).\n",
    "        # This ensures the input has the correct number of features (4 models * 30 days = 120).\n",
    "        stacking_preds = [\n",
    "            base_preds_scaled['LSTM'],\n",
    "            base_preds_scaled['GRU'],\n",
    "            base_preds_scaled['RNN'],\n",
    "            base_preds_scaled['Random_Forest']\n",
    "        ]\n",
    "        stacked_features = np.hstack(stacking_preds).reshape(1, -1)\n",
    "        \n",
    "        # The meta-learner was trained to predict 30 days, so we slice its output\n",
    "        final_pred_scaled = meta_learner_m.predict(stacked_features)[0][:future_days]\n",
    "        \n",
    "    elif model_name == 'Weighted_Ensemble':\n",
    "        print(\"  - Using Weighted Ensemble...\")\n",
    "        # Tile ARIMA to match the multi-step models for weighting\n",
    "        arima_30day = np.full((future_days,), base_preds_scaled['ARIMA'][0])\n",
    "        # Apply weights\n",
    "        weighted_sum = (\n",
    "            weights_m['LSTM'] * base_preds_scaled['LSTM'] +\n",
    "            weights_m['GRU'] * base_preds_scaled['GRU'] +\n",
    "            weights_m['RNN'] * base_preds_scaled['RNN'] +\n",
    "            weights_m['Moving Average'] * arima_30day\n",
    "        )\n",
    "        final_pred_scaled = weighted_sum\n",
    "\n",
    "    else:\n",
    "        # Default to the best model if the name is not recognized\n",
    "        print(f\"Warning: Model '{model_name}' not found for direct prediction. Defaulting to LSTM.\")\n",
    "        final_pred_scaled = base_preds_scaled['LSTM']\n",
    "\n",
    "    # --- Step 3: Descale the final prediction ---\n",
    "    final_pred_unscaled = scalers['Close'].inverse_transform(final_pred_scaled.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    print(\"‚úÖ Forecast generated successfully.\")\n",
    "    return final_pred_unscaled\n",
    "\n",
    "# --- Main Execution ---\n",
    "# 1. Consolidate all models into a single dictionary for easy access\n",
    "all_models = {\n",
    "    'LSTM': lstm_model, 'GRU': gru_model, 'RNN': rnn_model,\n",
    "    'Random_Forest': rf_model, 'ARIMA': fitted_arima,\n",
    "    'Stacked_Ensemble_Meta': meta_learner, 'Weighted_Ensemble_Weights': weights\n",
    "}\n",
    "\n",
    "# 2. Determine the best overall model from the final ranking\n",
    "best_model_name = min(all_models_performance, key=all_models_performance.get)\n",
    "best_model_mae = all_models_performance[best_model_name]\n",
    "print(f\"üèÜ Best overall model identified: '{best_model_name}' (MAE: {best_model_mae:.6f})\")\n",
    "\n",
    "# 3. Interactive loop for future prediction\n",
    "while True:\n",
    "    print(\"\\n--- Future Prediction Menu ---\")\n",
    "    # Create a map of all available models for prediction\n",
    "    available_models_list = sorted(all_models_performance.keys())\n",
    "    model_map = {str(i + 1): name for i, name in enumerate(available_models_list)}\n",
    "    \n",
    "    print(f\"d: Use default best model ({best_model_name})\")\n",
    "    for key, name in model_map.items():\n",
    "        print(f\"{key}: {name} (MAE: {all_models_performance[name]:.4f})\")\n",
    "    print(\"q: Quit\")\n",
    "    \n",
    "    choice = input(\"Select a model for future prediction [d]: \").strip().lower()\n",
    "    \n",
    "    if choice == 'q':\n",
    "        print(\"Exiting future prediction.\")\n",
    "        break\n",
    "    \n",
    "    chosen_model_name = best_model_name\n",
    "    if choice == 'd' or choice == '':\n",
    "        pass # Use default\n",
    "    elif choice in model_map:\n",
    "        chosen_model_name = model_map[choice]\n",
    "    else:\n",
    "        print(\"‚ùå Invalid choice. Please select from the list.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        days_input = input(\"Enter number of future days to predict [default: 30]: \").strip()\n",
    "        FUTURE_DAYS = int(days_input) if days_input else 30\n",
    "        \n",
    "        # Prepare the last known sequence from the test data\n",
    "        last_sequence = test_values[-PREDICTION_DAYS:]\n",
    "        \n",
    "        # Generate the predictions\n",
    "        future_predictions = generate_future_predictions(\n",
    "            chosen_model_name, FUTURE_DAYS, last_sequence, all_models, scalers, feature_columns\n",
    "        )\n",
    "        \n",
    "        # Create future dates and DataFrame\n",
    "        last_date = pd.to_datetime(df['Date'].iloc[-1])\n",
    "        future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=FUTURE_DAYS)\n",
    "        \n",
    "        future_df = pd.DataFrame({\n",
    "            'Date': future_dates,\n",
    "            'Predicted_Close': future_predictions,\n",
    "            'Model': chosen_model_name\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n‚úÖ Generated {FUTURE_DAYS} future predictions using '{chosen_model_name}'\")\n",
    "        print(f\"   Future prediction range: ${future_predictions.min():.2f} to ${future_predictions.max():.2f}\")\n",
    "        print(\"\\n--- First 10 Future Predictions ---\")\n",
    "        print(future_df.head(10).round(2))\n",
    "        \n",
    "        # Ask to run again or exit\n",
    "        rerun = input(\"\\nRun again with a different model? (y/n) [n]: \").strip().lower()\n",
    "        if rerun != 'y':\n",
    "            break\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An error occurred during prediction: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6754a111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prerequisite Checks ---\n",
    "try:\n",
    "    predictions_viz_data, all_models_performance, future_df, complete_data\n",
    "    chosen_model_name, best_model_name, best_mae, COMPANY, FUTURE_DAYS\n",
    "    print(\"‚úÖ All prerequisite data found. Generating the final dashboard...\")\n",
    "except NameError as e:\n",
    "    print(f\"‚ùå CRITICAL ERROR: A required variable is missing: {e}\")\n",
    "    print(\"   Please ensure all preceding cells were run successfully before creating this visualization.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data & Color Preparation ---\n",
    "# Ensure 'Open' column exists for candlestick chart\n",
    "if 'Open' not in complete_data.columns:\n",
    "    complete_data['Open'] = complete_data['Close'].shift(1).fillna(complete_data['Close'])\n",
    "\n",
    "# Define a professional and consistent color palette for the dashboard\n",
    "colors = {\n",
    "    'primary': '#005ea6',      # Strong Blue\n",
    "    'secondary': '#e87722',    # Bright Orange\n",
    "    'accent': '#d62728',       # Strong Red\n",
    "    'neutral': '#5a5a5a',      # Dark Gray\n",
    "    'up': '#008450',           # Green\n",
    "    'down': '#d62728',         # Red\n",
    "    'band': 'rgba(232, 119, 34, 0.2)' # Light Orange for confidence band\n",
    "}\n",
    "\n",
    "\n",
    "# --- Create Visualization Dashboard ---\n",
    "# The layout is strategically rearranged for a more logical narrative flow.\n",
    "# Row 2 now pairs the forecast detail with historical volume for contextual analysis.\n",
    "# Row 3 groups the two model performance metrics together.\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    subplot_titles=(\n",
    "        # Row 1: The main, overarching chart remains at the top.\n",
    "        '<b>Historical Price, Test Predictions & Future Forecast</b>', None,\n",
    "        # Row 2: Contextual charts - detailed price action and volume.\n",
    "        '<b>Forecast Detail vs. Recent History</b>', '<b>Daily Trading Volume</b>',\n",
    "        # Row 3: Model evaluation charts.\n",
    "        '<b>Model Performance (MAE)</b>', '<b>Prediction Error Distribution</b>'\n",
    "    ),\n",
    "    specs=[\n",
    "        [{\"colspan\": 2}, None],\n",
    "        [{}, {}],\n",
    "        [{}, {}]\n",
    "    ],\n",
    "    vertical_spacing=0.15,\n",
    "    horizontal_spacing=0.08,\n",
    "    row_heights=[0.5, 0.25, 0.25] # Allocate more space to the main chart\n",
    ")\n",
    "\n",
    "\n",
    "# --- Plot 1: Main Chart (Row 1, Col 1) ---\n",
    "# This plot combines historical data, model predictions, and the future forecast.\n",
    "# It provides the primary overview of the stock's performance and outlook.\n",
    "\n",
    "# Calculate the confidence band based on the standard deviation of all model predictions\n",
    "model_preds_for_std = predictions_viz_data[[col for col in predictions_viz_data.columns if col not in ['Date', 'Actual']]]\n",
    "ensemble_std = model_preds_for_std.std(axis=1)\n",
    "best_preds = predictions_viz_data.get(best_model_name)\n",
    "if best_preds is None:\n",
    "    best_preds = pd.Series([0] * len(predictions_viz_data)) # Placeholder if best model preds are missing\n",
    "\n",
    "# Add confidence band traces first so they render in the background\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=predictions_viz_data['Date'], y=best_preds + (2 * ensemble_std),\n",
    "    mode='lines', line=dict(width=0), showlegend=False, hoverinfo='none'\n",
    "), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=predictions_viz_data['Date'], y=best_preds - (2 * ensemble_std),\n",
    "    mode='lines', line=dict(width=0), fill='tonexty',\n",
    "    name='Confidence Band (¬±2œÉ)', fillcolor=colors['band'], hoverinfo='none'\n",
    "), row=1, col=1)\n",
    "\n",
    "# Add primary data traces\n",
    "fig.add_trace(go.Candlestick(x=complete_data['Date'], open=complete_data['Open'], high=complete_data['High'], low=complete_data['Low'], close=complete_data['Close'], name='Historical Price', increasing_line_color=colors['up'], decreasing_line_color=colors['down']), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=predictions_viz_data['Date'], y=predictions_viz_data['Actual'], mode='lines', name='Actual (Test Set)', line=dict(color='black', width=2.5)), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=predictions_viz_data['Date'], y=best_preds, mode='lines', name=f'Best Model: {best_model_name.replace(\"_\", \" \")}', line=dict(color=colors['secondary'], width=2, dash='dot')), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=future_df['Date'], y=future_df['Predicted_Close'], mode='lines', name=f'Future Forecast ({chosen_model_name.replace(\"_\", \" \")})', line=dict(color=colors['accent'], width=3, dash='dash')), row=1, col=1)\n",
    "\n",
    "\n",
    "# --- Plot 2: Forecast Detail (Row 2, Col 1) ---\n",
    "# A zoomed-in view of the most recent history and the forecast period.\n",
    "recent_data = complete_data.tail(90)\n",
    "fig.add_trace(go.Scatter(x=recent_data['Date'], y=recent_data['Close'], mode='lines', name='Recent History', line=dict(color=colors['neutral'], width=2)), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(x=future_df['Date'], y=future_df['Predicted_Close'], mode='lines+markers', name='Forecast Detail', line=dict(color=colors['accent'], width=2), marker=dict(size=5)), row=2, col=1)\n",
    "\n",
    "\n",
    "# --- Plot 3: Volume Analysis (Row 2, Col 2) ---\n",
    "# Shows trading volume, colored by whether the day's price went up or down.\n",
    "volume_colors = [colors['up'] if c >= o else colors['down'] for o, c in zip(complete_data['Open'], complete_data['Close'])]\n",
    "fig.add_trace(go.Bar(\n",
    "    x=complete_data['Date'], y=complete_data['Volume'],\n",
    "    name='Volume', marker_color=volume_colors, opacity=0.8\n",
    "), row=2, col=2)\n",
    "\n",
    "\n",
    "# --- Plot 4: Model Performance (Row 3, Col 1) ---\n",
    "# A horizontal bar chart for better readability of model names, ranked by MAE.\n",
    "sorted_perf = sorted(all_models_performance.items(), key=lambda item: item [1], reverse=True)\n",
    "model_names_sorted = [item [0].replace('_', ' ') for item in sorted_perf]\n",
    "model_maes_sorted = [item [1] for item in sorted_perf]\n",
    "fig.add_trace(go.Bar(\n",
    "    y=model_names_sorted, x=model_maes_sorted,\n",
    "    orientation='h', name='Model MAE',\n",
    "    marker_color=colors['primary'],\n",
    "    text=[f'{mae:.3f}' for mae in model_maes_sorted],\n",
    "    textposition='auto'\n",
    "), row=3, col=1)\n",
    "\n",
    "\n",
    "# --- Plot 5: Error Distribution (Row 3, Col 2) ---\n",
    "# A histogram showing the distribution of the best model's prediction errors.\n",
    "errors = predictions_viz_data['Actual'] - predictions_viz_data.get(best_model_name, pd.Series([0] * len(predictions_viz_data)))\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=errors, name='Error Frequency',\n",
    "    marker_color=colors['primary'], nbinsx=30\n",
    "), row=3, col=2)\n",
    "# Add a vertical line to indicate the mean error\n",
    "fig.add_vline(x=errors.mean(), line_width=2, line_dash=\"dash\", line_color=colors['accent'],\n",
    "              annotation_text=f\"Mean Error: {errors.mean():.3f}\",\n",
    "              annotation_position=\"top right\", row=3, col=2)\n",
    "\n",
    "\n",
    "# --- Final Layout Updates ---\n",
    "# This section sets the overall theme, title, legend, and axis properties for the entire figure.\n",
    "fig.update_layout(\n",
    "    title_text=f'<b>{COMPANY} Comprehensive Stock Analysis & Future Predictions</b><br><sup>'\n",
    "               f'Best Overall Model: <b>{best_model_name.replace(\"_\", \" \")}</b> (MAE: {best_mae:.4f}) | '\n",
    "               f'Future Forecast Using: <b>{chosen_model_name.replace(\"_\", \" \")}</b> for {FUTURE_DAYS} days</sup>',\n",
    "    height=1100, # Adjusted height for a more compact view\n",
    "    template='plotly_white',\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=0.55, xanchor=\"right\", x=0.9), # Increased y to move legend down\n",
    "    hovermode='x unified',\n",
    "    bargap=0.1,\n",
    "    font=dict(family=\"Arial, sans-serif\", size=12)\n",
    ")\n",
    "\n",
    "# Update all axes titles and styles for clarity and consistency in the new layout\n",
    "fig.update_yaxes(title_text=\"Price ($)\", row=1, col=1, title_font_size=12)\n",
    "fig.update_yaxes(title_text=\"Price ($)\", row=2, col=1, title_font_size=12)\n",
    "fig.update_yaxes(title_text=\"Volume\", row=2, col=2, title_font_size=12)\n",
    "fig.update_xaxes(title_text=\"Model\", row=3, col=1, title_font_size=12)\n",
    "fig.update_yaxes(showticklabels=True, row=3, col=1) # Ensure y-axis labels (model names) are visible\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=3, col=2, title_font_size=12)\n",
    "fig.update_xaxes(title_text=\"Prediction Error ($)\", row=3, col=2, title_font_size=12)\n",
    "\n",
    "# Remove rangeslider from the main chart to save space\n",
    "fig.update_xaxes(rangeslider_visible=False, row=1, col=1)\n",
    "\n",
    "# Hide redundant legends for plots where it's not needed\n",
    "fig.update_traces(showlegend=False, selector=dict(type='bar'))\n",
    "fig.update_traces(showlegend=False, selector=dict(type='histogram'))\n",
    "fig.update_traces(showlegend=False, selector=dict(name='Recent History'))\n",
    "fig.update_traces(showlegend=False, selector=dict(name='Forecast Detail'))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"‚úÖ Interactive visualization with improved legend spacing created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2adf397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Results and Final Summary\n",
    "\n",
    "# Create results export\n",
    "results_export = {\n",
    "    'Model_Performance': {\n",
    "        'Individual_Models': {\n",
    "            'LSTM_MAE': float(mean_absolute_error(aligned_y_test, aligned_lstm_preds)),\n",
    "            'GRU_MAE': float(mean_absolute_error(aligned_y_test, aligned_gru_preds)),\n",
    "            'RNN_MAE': float(mean_absolute_error(aligned_y_test, aligned_rnn_preds)),\n",
    "            'RandomForest_MAE': float(mean_absolute_error(aligned_y_test, aligned_rf_preds)),\n",
    "            'MovingAverage_MAE': float(mean_absolute_error(aligned_y_test[:, 0], aligned_arima_preds))\n",
    "        },\n",
    "        'Ensemble_Models': {\n",
    "            'Ensemble_MA_LSTM_MAE': float(ensemble_mae_arima_lstm),\n",
    "            'Ensemble_MA_LSTM_GRU_MAE': float(ensemble_mae_arima_lstm_gru),\n",
    "            'Ensemble_MA_LSTM_GRU_RF_MAE': float(ensemble_mae_arima_lstm_gru_rf),\n",
    "            'Ensemble_All_MAE': float(ensemble_mae_all)\n",
    "        },\n",
    "        'Best_Model': best_ensemble,\n",
    "        'Best_MAE': float(best_mae)\n",
    "    },\n",
    "    'Future_Predictions': {\n",
    "        'Prediction_Days': FUTURE_DAYS,\n",
    "        'Current_Price': float(complete_data['Close'].iloc[-1]),\n",
    "        'Predicted_Price_30_Days': float(future_predictions[-1]),\n",
    "        'Price_Change': float(future_predictions[-1] - complete_data['Close'].iloc[-1]),\n",
    "        'Percentage_Change': float(((future_predictions[-1] / complete_data['Close'].iloc[-1]) - 1) * 100),\n",
    "        'Predictions': future_predictions.tolist(),\n",
    "        'Prediction_Dates': [date.strftime('%Y-%m-%d') for date in future_dates]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save future predictions\n",
    "future_export_df = pd.DataFrame({\n",
    "    'Date': future_dates,\n",
    "    'Predicted_Close_Price': future_predictions,\n",
    "    'Model_Used': best_ensemble,\n",
    "    'Confidence_Level': 'High' if best_mae < 5.0 else 'Medium' if best_mae < 10.0 else 'Low'\n",
    "})\n",
    "future_predictions_filename = f\"{DATA_DIR}/{COMPANY}_future_predictions_{FUTURE_DAYS}days.csv\"\n",
    "future_export_df.to_csv(future_predictions_filename, index=False)\n",
    "\n",
    "# Save performance comparison\n",
    "performance_df = pd.DataFrame({\n",
    "    'Model': ['LSTM', 'GRU', 'RNN', 'Random Forest', 'Moving Average'] + list(ensemble_models.keys()),\n",
    "    'MAE': [\n",
    "        mean_absolute_error(aligned_y_test, aligned_lstm_preds),\n",
    "        mean_absolute_error(aligned_y_test, aligned_gru_preds),\n",
    "        mean_absolute_error(aligned_y_test, aligned_rnn_preds),\n",
    "        mean_absolute_error(aligned_y_test, aligned_rf_preds),\n",
    "        mean_absolute_error(aligned_y_test[:, 0], aligned_arima_preds)\n",
    "    ] + list(ensemble_models.values()),\n",
    "    'Model_Type': ['Individual'] * 5 + ['Ensemble'] * len(ensemble_models)\n",
    "})\n",
    "performance_filename = f\"{DATA_DIR}/{COMPANY}_model_performance_comparison.csv\"\n",
    "performance_df.to_csv(performance_filename, index=False)\n",
    "# Define individual model names\n",
    "individual_models = ['LSTM', 'GRU', 'RNN', 'Random Forest', 'Moving Average']\n",
    "\n",
    "\n",
    "print(f\"‚úÖ Future predictions saved to: {future_predictions_filename}\")\n",
    "print(f\"‚úÖ Model performance comparison saved to: {performance_filename}\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n=== FINAL ANALYSIS SUMMARY ===\")\n",
    "print(f\"Stock Symbol: {COMPANY}\")\n",
    "print(f\"Analysis Period: {TRAIN_START} to {TRAIN_END}\")\n",
    "print(f\"Total Models Tested: {len(individual_models) + len(ensemble_models)}\")\n",
    "print(f\"Best Performing Model: {best_ensemble}\")\n",
    "print(f\"Best Model MAE: {best_mae:.6f}\")\n",
    "print(f\"Current Stock Price: ${complete_data['Close'].iloc[-1]:.2f}\")\n",
    "print(f\"30-Day Price Prediction: ${future_predictions[-1]:.2f}\")\n",
    "print(f\"Predicted Price Change: ${future_predictions[-1] - complete_data['Close'].iloc[-1]:.2f}\")\n",
    "print(f\"Predicted Percentage Change: {((future_predictions[-1] / complete_data['Close'].iloc[-1]) - 1) * 100:.2f}%\")\n",
    "\n",
    "# Model ranking\n",
    "print(\"\\n=== MODEL PERFORMANCE RANKING ===\")\n",
    "all_models_performance = {\n",
    "    'LSTM': mean_absolute_error(aligned_y_test, aligned_lstm_preds),\n",
    "    'GRU': mean_absolute_error(aligned_y_test, aligned_gru_preds),\n",
    "    'RNN': mean_absolute_error(aligned_y_test, aligned_rnn_preds),\n",
    "    'Random Forest': mean_absolute_error(aligned_y_test, aligned_rf_preds),\n",
    "    'Moving Average': mean_absolute_error(aligned_y_test[:, 0], aligned_arima_preds),\n",
    "    **ensemble_models\n",
    "}\n",
    "sorted_models = sorted(all_models_performance.items(), key=lambda x: x[1])\n",
    "for i, (model, mae) in enumerate(sorted_models, 1):\n",
    "    print(f\"{i}. {model}: MAE = {mae:.6f}\")\n",
    "\n",
    "# Investment recommendation\n",
    "price_change_pct = ((future_predictions[-1] / complete_data['Close'].iloc[-1]) - 1) * 100\n",
    "recommendation = (\n",
    "    \"STRONG BUY\" if price_change_pct > 5 else\n",
    "    \"BUY\" if price_change_pct > 2 else\n",
    "    \"HOLD\" if price_change_pct > -2 else\n",
    "    \"SELL\" if price_change_pct > -5 else\n",
    "    \"STRONG SELL\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüí° INVESTMENT RECOMMENDATION: {recommendation}\")\n",
    "print(f\"   Based on predicted {price_change_pct:.2f}% price change over 30 days\")\n",
    "print(f\"   Model confidence: {'High' if best_mae < 5.0 else 'Medium' if best_mae < 10.0 else 'Low'}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE - ALL VISUALIZATIONS AND PREDICTIONS READY!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
